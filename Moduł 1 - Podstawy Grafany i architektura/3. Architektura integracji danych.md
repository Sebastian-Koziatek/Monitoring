![Architektura integracji danych w Grafana](../grafiki/009-grafana-integration.png)

## Wprowadzenie

Grafana jest platformą wizualizacji danych, która nie przechowuje danych metryk, logów ani śladów (traces) – jej kluczową funkcją jest integracja z zewnętrznymi źródłami danych (datasources) i prezentacja tych danych w formie dashboardów, alertów i eksploracji ad-hoc. Architektura integracji danych w Grafanie opiera się na pluginowalnym systemie datasources, który umożliwia podłączenie dziesiątek różnych backendów – od time series databases (Prometheus, InfluxDB, Graphite) przez relacyjne bazy danych (PostgreSQL, MySQL) po systemy logów (Loki, Elasticsearch) i APM (Tempo, Jaeger).

Niniejszy dokument opisuje architekturę integracji danych w Grafanie, koncentrując się na mechanizmach query processing, proxy datasources, cachingu, uwierzytelniania oraz provisioning. Zrozumienie tych mechanizmów jest kluczowe dla efektywnej konfiguracji Grafany w środowiskach produkcyjnych, gdzie wydajność, bezpieczeństwo i skalowalność są priorytetami.

---

## Architektura wysokiego poziomu

### Model proxy datasource

Grafana działa jako proxy między użytkownikiem a źródłem danych. Zapytania (queries) pochodzące z dashboardów lub Explore nie są wykonywane bezpośrednio z przeglądarki użytkownika, lecz przechodzą przez backend Grafany:

```
[Przeglądarka użytkownika] 
    ↓ HTTP Request (query dashboard)
[Grafana Backend - port 3000]
    ↓ Query Processing
    ↓ Authentication/Authorization
    ↓ Query Translation
[Grafana Datasource Plugin]
    ↓ HTTP/gRPC Request
[Zewnętrzne źródło danych - Prometheus/Loki/PostgreSQL/etc.]
    ↓ Query Execution
[Grafana Datasource Plugin]
    ↓ Data Transformation
    ↓ Response Formatting (JSON)
[Grafana Backend]
    ↓ HTTP Response
[Przeglądarka użytkownika - rendering]
```

**Konsekwencje architektury proxy:**

1. **Bezpieczeństwo:** Credentials do datasources (hasła, tokeny API, certyfikaty) są przechowywane w bazie danych Grafany i nigdy nie są eksponowane do przeglądarki użytkownika. Zapytania są uwierzytelniane przez backend Grafany.

2. **Kontrola dostępu:** Grafana może implementować RBAC (Role-Based Access Control) na poziomie datasource, dashboardu i panelu, niezależnie od mechanizmów autoryzacji w samym datasource.

3. **Wydajność:** Backend Grafany może cachować wyniki zapytań, aggregować zapytania do tego samego datasource i optymalizować query execution.

4. **Network isolation:** Datasources mogą być w prywatnych sieciach niedostępnych dla użytkowników końcowych. Tylko Grafana wymaga connectivity do datasources.

5. **Consistent API:** Użytkownicy i dashboardy korzystają z jednolitego API Grafany, niezależnie od różnic w API poszczególnych datasources.

**Alternatywa: Browser datasources (rzadkie)**

Niektóre datasources (np. TestData, niektóre pluginy community) mogą działać w trybie "browser", gdzie zapytania są wykonywane bezpośrednio z przeglądarki. To podejście jest używane tylko dla datasources bez wrażliwych credentials lub datasources czysto syntetycznych (testowych).

---

## Typy datasources

### Time Series Databases (TSDB)

Datasources zoptymalizowane pod przechowywanie i query metryk szeregów czasowych:

| Datasource | Protokół | Domyślny port | Typ danych | Język zapytań |
|---|---|---|---|---|
| **Prometheus** | HTTP | 9090 | Metryki (time series) | PromQL |
| **Graphite** | HTTP | 8080 | Metryki (time series) | Graphite query syntax |
| **InfluxDB** | HTTP | 8086 | Metryki (time series) | InfluxQL / Flux |
| **Mimir** | HTTP | 9009 (query) | Metryki (time series) | PromQL |
| **Thanos** | HTTP | 10902 | Metryki (time series) | PromQL |
| **Victoria Metrics** | HTTP | 8428 | Metryki (time series) | PromQL, MetricsQL |

**Charakterystyka:**
- Obsługa time range queries z agregacjami (sum, avg, rate, etc.)
- Zwracają dane w formacie time series (timestamp, value)
- Query cache friendly (dane historyczne są immutable)

### Log Management Systems

Datasources do agregacji, wyszukiwania i analizy logów:

| Datasource | Protokół | Domyślny port | Typ danych | Język zapytań |
|---|---|---|---|---|
| **Loki** | HTTP | 3100 | Logi (log streams) | LogQL |
| **Elasticsearch** | HTTP | 9200 | Logi, full-text search | Lucene / Elasticsearch DSL |
| **Splunk** | HTTP | 8089 (API) | Logi | SPL (Search Processing Language) |
| **CloudWatch Logs** | AWS API | 443 (HTTPS) | Logi (AWS) | CloudWatch Logs Insights |

**Charakterystyka:**
- Full-text search w logach
- Agregacje na podstawie labels/fields
- Zwracają logi jako structured streams lub documents

### Distributed Tracing Systems

Datasources do distributed tracing (APM):

| Datasource | Protokół | Domyślny port | Typ danych | Język zapytań |
|---|---|---|---|---|
| **Tempo** | HTTP | 3200 | Traces | TraceQL |
| **Jaeger** | HTTP | 16686 | Traces | Jaeger Query API |
| **Zipkin** | HTTP | 9411 | Traces | Zipkin API |

**Charakterystyka:**
- Trace visualization (spans, dependencies)
- Service maps
- Latency analysis

### Relacyjne i NoSQL bazy danych

Datasources do queryowania danych biznesowych:

| Datasource | Protokół | Domyślny port | Typ danych | Język zapytań |
|---|---|---|---|---|
| **PostgreSQL** | PostgreSQL protocol | 5432 | Dane relacyjne | SQL |
| **MySQL** | MySQL protocol | 3306 | Dane relacyjne | SQL |
| **Microsoft SQL Server** | TDS | 1433 | Dane relacyjne | T-SQL |
| **MongoDB** | MongoDB protocol | 27017 | Dokumenty (NoSQL) | MongoDB Query Language |
| **Redis** | Redis protocol | 6379 | Key-value | Redis commands |

**Charakterystyka:**
- Arbitrary SQL queries
- Time series z timestamp column
- Transformacje danych na poziomie SQL (GROUP BY, JOIN)

### Cloud-native datasources

Datasources dla platform chmurowych:

- **CloudWatch** (AWS) - metryki, logi, traces
- **Azure Monitor** (Azure) - metryki, logi
- **Google Cloud Monitoring** (GCP) - metryki, logi, traces
- **Datadog** - metryki, logi, traces (vendor-specific)

---

## Cykl życia zapytania (Query Lifecycle)

### Faza 1: Query Execution Request

Użytkownik otwiera dashboard lub panel w Explore. Frontend Grafany (przeglądarka) wysyła HTTP request do Grafana Backend:

```http
POST /api/ds/query HTTP/1.1
Host: grafana.example.com
Content-Type: application/json
Authorization: Bearer <session_token>

{
  "queries": [
    {
      "refId": "A",
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus-prod"
      },
      "expr": "rate(http_requests_total[5m])",
      "range": true,
      "instant": false
    }
  ],
  "from": "now-1h",
  "to": "now"
}
```

**Elementy requestu:**
- `queries[]` – lista zapytań do wykonania (może być wiele na jeden request)
- `refId` – identyfikator query w dashboardzie (A, B, C...)
- `datasource.uid` – unikalny identyfikator datasource
- `expr` – query w języku datasource (PromQL, SQL, LogQL)
- `from/to` – time range

### Faza 2: Authorization & Validation

Grafana Backend weryfikuje:

1. **Session authentication:** Czy użytkownik jest zalogowany i ma ważną sesję?
2. **Datasource permissions:** Czy użytkownik ma dostęp do datasource `prometheus-prod`?
3. **Query permissions:** Czy użytkownik ma uprawnienia do wykonania tego typu zapytania? (Enterprise RBAC)
4. **Query validation:** Czy query jest poprawny składniowo?

Jeśli którykolwiek z warunków nie jest spełniony, zwracany jest błąd `403 Forbidden` lub `400 Bad Request`.

### Faza 3: Datasource Plugin Invocation

Grafana Backend ładuje odpowiedni datasource plugin (w tym przypadku Prometheus) i wywołuje jego metodę `Query()`:

```go
// Pseudo-kod wewnętrzny Grafana Backend
plugin := datasourceRegistry.Get("prometheus")
response, err := plugin.Query(ctx, QueryRequest{
    Queries:   request.Queries,
    TimeRange: TimeRange{From: request.From, To: request.To},
})
```

**Datasource plugin wykonuje:**

1. **Query translation:** Przekształca abstrakcyjne query Grafany na natywne query datasource (np. Prometheus API call).
2. **Credentials injection:** Pobiera credentials z konfiguracji datasource (URL, auth token, TLS certs) z bazy danych Grafany.
3. **HTTP/gRPC request:** Wykonuje request do zewnętrznego datasource.

Przykład requestu do Prometheus:

```http
GET /api/v1/query_range?query=rate(http_requests_total[5m])&start=1706608800&end=1706612400&step=15 HTTP/1.1
Host: prometheus.internal:9090
Authorization: Bearer <prometheus_token>
```

### Faza 4: Data Retrieval & Transformation

1. **Datasource response:** Prometheus zwraca dane w swoim natywnym formacie (JSON).

```json
{
  "status": "success",
  "data": {
    "resultType": "matrix",
    "result": [
      {
        "metric": {"__name__": "http_requests_total", "status": "200"},
        "values": [
          [1706608800, "150.5"],
          [1706608815, "152.3"],
          ...
        ]
      }
    ]
  }
}
```

2. **Data transformation:** Datasource plugin transformuje dane do uniwersalnego formatu Grafana Data Frame.

```json
{
  "frames": [
    {
      "name": "http_requests_total",
      "fields": [
        {
          "name": "Time",
          "type": "time",
          "values": [1706608800000, 1706608815000, ...]
        },
        {
          "name": "Value",
          "type": "number",
          "values": [150.5, 152.3, ...]
        }
      ],
      "meta": {
        "preferredVisualisationType": "graph"
      }
    }
  ]
}
```

**Grafana Data Frame** to uniwersalny format danych używany wewnętrznie, niezależny od datasource. Umożliwia jednolite transformacje (agregacje, filtrowanie, matematyka) niezależnie od źródła danych.

### Faza 5: Response Caching (opcjonalne)

Jeśli datasource ma włączony caching, Grafana może cache'ować response:

- **Query cache:** Bazuje na query string + time range + datasource UID
- **TTL:** Configurable per datasource (domyślnie wyłączone dla większości datasources)
- **Invalidation:** Automatycznie po upływie TTL

**Konfiguracja cache w `grafana.ini`:**

```ini
[caching]
enabled = true
backend = redis

[caching.redis]
address = redis:6379
password = <redis_password>
db = 0
```

**Uwaga:** Caching jest dostępny domyślnie tylko w Grafana Enterprise. W OSS dostępny dla niektórych datasources (np. CloudWatch).

### Faza 6: Response to Frontend

Grafana Backend zwraca sformatowaną odpowiedź do przeglądarki:

```http
HTTP/1.1 200 OK
Content-Type: application/json

{
  "results": {
    "A": {
      "status": 200,
      "frames": [...]
    }
  }
}
```

Frontend renderuje dane w panelu (graph, table, stat, etc.).

---

## Konfiguracja datasources

### Metoda 1: UI Configuration

Datasources można konfigurować przez interfejs webowy Grafany:

**Ścieżka:** Configuration → Data sources → Add data source

**Przykład konfiguracji Prometheus:**

| Parametr | Wartość | Opis |
|---|---|---|
| **Name** | `Prometheus Production` | Nazwa wyświetlana w UI |
| **URL** | `http://prometheus.internal:9090` | Endpoint Prometheus API |
| **Access** | `Server (default)` | Proxy przez backend Grafany |
| **Auth** | Basic auth / Bearer token | Typ uwierzytelniania |
| **Basic Auth User** | `grafana` | Username (jeśli basic auth) |
| **Basic Auth Password** | `<password>` | Password (encrypted w bazie) |
| **Custom HTTP Headers** | `X-Scope-OrgID: tenant1` | Dodatkowe headers (np. dla multi-tenancy) |
| **Timeout** | `60s` | Timeout HTTP requests |
| **Default** | Yes/No | Czy datasource jest domyślny dla nowych paneli? |

**Zapisanie konfiguracji:**

Konfiguracja jest zapisywana w bazie danych Grafany (tabela `data_source`). Credentials są szyfrowane za pomocą `secret_key` z `grafana.ini`.

**Testowanie połączenia:**

Po konfiguracji należy kliknąć "Save & Test". Grafana wykona testowe zapytanie do datasource i zweryfikuje connectivity.

### Metoda 2: Provisioning (zalecane dla production)

Provisioning umożliwia deklaratywne zarządzanie datasources poprzez pliki YAML. Jest to preferowana metoda w środowiskach Infrastructure as Code (IaC).

**Lokalizacja plików provisioning:**
```
/etc/grafana/provisioning/datasources/
```

**Przykład: `datasources.yml`**

```yaml
apiVersion: 1

datasources:
  # Prometheus Production
  - name: Prometheus Production
    type: prometheus
    uid: prometheus-prod
    access: proxy
    url: http://prometheus.internal:9090
    isDefault: true
    editable: false
    jsonData:
      timeInterval: 15s
      httpMethod: POST
      queryTimeout: 60s
      customQueryParameters: ""
    secureJsonData:
      # Credentials (encrypted by Grafana)
      httpHeaderValue1: "Bearer ${PROMETHEUS_TOKEN}"

  # Loki Production
  - name: Loki Production
    type: loki
    uid: loki-prod
    access: proxy
    url: http://loki.internal:3100
    editable: false
    jsonData:
      maxLines: 1000
      timeout: 60
    secureJsonData:
      httpHeaderValue1: "Bearer ${LOKI_TOKEN}"

  # PostgreSQL Business Metrics
  - name: PostgreSQL Metrics
    type: postgres
    uid: postgres-metrics
    access: proxy
    url: postgres.internal:5432
    database: metrics_db
    user: grafana_ro
    editable: false
    jsonData:
      sslmode: require
      postgresVersion: 1600  # PostgreSQL 16.x
      timescaledb: false
    secureJsonData:
      password: ${POSTGRES_PASSWORD}

  # CloudWatch (AWS)
  - name: AWS CloudWatch
    type: cloudwatch
    uid: cloudwatch-prod
    access: proxy
    editable: false
    jsonData:
      authType: keys
      defaultRegion: eu-central-1
    secureJsonData:
      accessKey: ${AWS_ACCESS_KEY_ID}
      secretKey: ${AWS_SECRET_ACCESS_KEY}

deleteDatasources:
  # Lista datasources do usunięcia (jeśli istnieją)
  - name: Old Prometheus
    orgId: 1
```

**Kluczowe parametry:**

- `uid` – Unikalny identyfikator datasource. Powinien być stabilny (nie zmienia się między restartami). UID są używane w dashboardach, więc zmiana UID zepsuje istniejące dashboardy.
- `access: proxy` – Wszystkie zapytania przechodzą przez backend Grafany (standardowe).
- `editable: false` – Użytkownicy nie mogą modyfikować datasource przez UI (wymuszenie konfiguracji z provisioning).
- `jsonData` – Datasource-specific settings (JSON).
- `secureJsonData` – Credentials i sekrety (encrypted w bazie danych).

**Zmienne środowiskowe:**

Provisioning wspiera interpolację zmiennych środowiskowych:

```yaml
secureJsonData:
  password: ${POSTGRES_PASSWORD}
```

Zmienne mogą być ustawione w:
- Environment variables systemu
- Plik `.env` (jeśli używasz Docker)
- Secrets management (Kubernetes Secrets, Vault)

**Docker Compose z provisioning:**

```yaml
services:
  grafana:
    image: grafana/grafana-oss:11.4.0
    volumes:
      - ./provisioning/datasources:/etc/grafana/provisioning/datasources
    environment:
      - PROMETHEUS_TOKEN=secret_token_123
      - LOKI_TOKEN=secret_token_456
      - POSTGRES_PASSWORD=secure_password_789
```

**Reload provisioning bez restartu:**

Grafana automatycznie wykrywa zmiany w plikach provisioning i reload'uje konfigurację (nie wymaga restartu dla większości zmian).

Weryfikacja:
```bash
# Sprawdź logi Grafany
journalctl -u grafana-server -f | grep provisioning
```

---

## Authentication do datasources

### 1. No Authentication

Datasource jest publicznie dostępny (rzadkie w produkcji).

```yaml
jsonData: {}
secureJsonData: {}
```

### 2. Basic Authentication

Username + password w nagłówku `Authorization: Basic <base64>`.

```yaml
jsonData:
  basicAuth: true
  basicAuthUser: grafana_user
secureJsonData:
  basicAuthPassword: ${DATASOURCE_PASSWORD}
```

**Zastosowanie:** Prometheus z basic auth, Elasticsearch, HTTP APIs.

### 3. Bearer Token

Token w nagłówku `Authorization: Bearer <token>`.

```yaml
jsonData:
  httpHeaderName1: "Authorization"
secureJsonData:
  httpHeaderValue1: "Bearer ${API_TOKEN}"
```

**Zastosowanie:** Prometheus z token auth, Loki, custom APIs.

### 4. Custom HTTP Headers

Dowolne HTTP headers (np. dla multi-tenancy).

```yaml
jsonData:
  httpHeaderName1: "X-Scope-OrgID"
  httpHeaderName2: "X-Custom-Header"
secureJsonData:
  httpHeaderValue1: "tenant-123"
  httpHeaderValue2: "custom-value"
```

**Zastosowanie:** Prometheus/Loki multi-tenant, Cortex, Mimir.

### 5. TLS Client Certificates

Mutual TLS (mTLS) authentication.

```yaml
jsonData:
  tlsAuth: true
  tlsAuthWithCACert: true
  serverName: "prometheus.internal"  # SNI
secureJsonData:
  tlsCACert: |
    -----BEGIN CERTIFICATE-----
    <CA_CERTIFICATE>
    -----END CERTIFICATE-----
  tlsClientCert: |
    -----BEGIN CERTIFICATE-----
    <CLIENT_CERTIFICATE>
    -----END CERTIFICATE-----
  tlsClientKey: |
    -----BEGIN PRIVATE KEY-----
    <CLIENT_PRIVATE_KEY>
    -----END PRIVATE KEY-----
```

**Zastosowanie:** Produkcyjne deploymenty z wysokimi wymaganiami bezpieczeństwa.

### 6. AWS Authentication

Dla datasources AWS (CloudWatch, Athena, Timestream).

**Option A: IAM Keys**

```yaml
jsonData:
  authType: keys
  defaultRegion: eu-central-1
secureJsonData:
  accessKey: ${AWS_ACCESS_KEY_ID}
  secretKey: ${AWS_SECRET_ACCESS_KEY}
```

**Option B: IAM Role (zalecane w AWS)**

```yaml
jsonData:
  authType: default  # Używa IAM role z EC2 instance profile
  defaultRegion: eu-central-1
```

**Option C: Assume Role**

```yaml
jsonData:
  authType: arn
  assumeRoleArn: arn:aws:iam::123456789012:role/GrafanaAssumeRole
  defaultRegion: eu-central-1
secureJsonData:
  accessKey: ${AWS_ACCESS_KEY_ID}
  secretKey: ${AWS_SECRET_ACCESS_KEY}
```

### 7. Azure Managed Identity

Dla Azure Monitor datasources.

```yaml
jsonData:
  azureAuthType: msi  # Managed Service Identity
```

### 8. Google Cloud Service Account

Dla Google Cloud datasources.

```yaml
jsonData:
  authenticationType: gce  # GCE metadata server
```

Lub:

```yaml
jsonData:
  authenticationType: jwt
secureJsonData:
  privateKey: ${GCP_SERVICE_ACCOUNT_KEY}
```

---

## Proxy vs Direct Access

Grafana wspiera dwa tryby dostępu do datasources:

### Server (Proxy) – domyślny i zalecany

```yaml
access: proxy
```

**Charakterystyka:**
- Wszystkie zapytania przechodzą przez backend Grafany
- Credentials są przechowywane na serwerze Grafany
- Datasources mogą być w prywatnych sieciach niedostępnych dla użytkowników
- Grafana może implementować caching, rate limiting, query logging
- Wymaga connectivity między Grafana Backend a datasources

**Network flow:**
```
[User Browser] → [Grafana Backend] → [Datasource]
```

**Użycie w produkcji:** Ponad 95% przypadków.

### Browser (Direct) – specjalne przypadki

```yaml
access: direct
```

**Charakterystyka:**
- Zapytania są wykonywane bezpośrednio z przeglądarki użytkownika
- Datasource musi być dostępny z sieci użytkownika
- Credentials są wysyłane do przeglądarki (NIEBEZPIECZNE)
- Brak proxy features (caching, rate limiting)
- CORS musi być włączony na datasource

**Network flow:**
```
[User Browser] → [Datasource]
```

**Użycie:** Tylko dla datasources bez credentials (TestData, publiczne APIs) lub w bardzo specyficznych scenariuszach (np. embedded Grafana w aplikacji klienta).

**UWAGA BEZPIECZEŃSTWA:** Tryb `direct` eksponuje credentials do przeglądarki. NIGDY nie używaj dla produkcyjnych datasources z wrażliwymi danymi.

---

## Query Caching

### Grafana OSS – ograniczony caching

W Grafana OSS caching jest dostępny dla:
- **CloudWatch** – cache responses z AWS (domyślnie 5 minut)
- **Azure Monitor** – cache responses z Azure

Dla innych datasources (Prometheus, Loki, PostgreSQL) caching wymaga Grafana Enterprise.

### Grafana Enterprise – Query Caching

Grafana Enterprise oferuje uniwersalny query cache dla wszystkich datasources.

**Konfiguracja w `grafana.ini`:**

```ini
[caching]
enabled = true

# Backend: memory, redis, memcached
backend = redis

[caching.redis]
address = redis.internal:6379
password = ${REDIS_PASSWORD}
db = 0
# Connection pool
pool_size = 10
```

**Cache TTL per datasource:**

```yaml
# Provisioning datasource z cache TTL
datasources:
  - name: Prometheus
    type: prometheus
    jsonData:
      cacheLevel: Low     # Low, Medium, High
      incrementalQuerying: true
      incrementalQueryOverlapWindow: 10m
```

**Cache levels:**
- **Low:** 1 minuta TTL
- **Medium:** 5 minut TTL
- **High:** 10 minut TTL

**Incremental Querying:**

Dla time series datasources (Prometheus, Graphite), Grafana Enterprise może cache'ować historyczne dane i wykonywać tylko incremental queries dla najnowszych danych:

```
[Cached: 00:00-00:50] + [Fresh query: 00:50-01:00] = [Full range: 00:00-01:00]
```

Redukuje load na datasources dla często odświeżanych dashboardów.

---

## Best Practices

### 1. Używaj Provisioning dla datasources

Provisioning zapewnia:
- Reproducibility (Infrastructure as Code)
- Version control (Git)
- Consistency między środowiskami (dev, staging, prod)
- Automated deployment (CI/CD)

### 2. Używaj stable UIDs dla datasources

UID są używane w dashboardach. Zmiana UID zepsuje wszystkie dashboardy odwołujące się do tego datasource.

**Dobra praktyka:**
```yaml
uid: prometheus-prod  # Stable, descriptive UID
```

**Zła praktyka:**
```yaml
uid: abc123xyz  # Losowy, nieczytelny UID
```

### 3. Nie używaj `isDefault: true` dla wielu datasources

Tylko jeden datasource danego typu powinien być domyślny. Wielokrotne `isDefault: true` może powodować nieoczekiwane zachowanie.

### 4. Używaj `editable: false` dla provisioned datasources

Zapobiega to manualnym zmianom w UI, które zostaną nadpisane przy następnym provisioning.

### 5. Używaj zmiennych środowiskowych dla credentials

**Dobra praktyka:**
```yaml
secureJsonData:
  password: ${POSTGRES_PASSWORD}
```

**Zła praktyka:**
```yaml
secureJsonData:
  password: "hardcoded_password_123"  # Plaintext w Git
```

### 6. Konfiguruj timeouty dla datasources

Domyślne timeouty mogą być zbyt krótkie dla ciężkich zapytań:

```yaml
jsonData:
  queryTimeout: 300s  # 5 minut dla heavy queries
  timeout: 60         # HTTP timeout (sekundy)
```

### 7. Używaj TLS dla datasources w produkcji

```yaml
jsonData:
  tlsSkipVerify: false  # Weryfikuj certyfikaty
  tlsAuth: true         # Używaj mTLS jeśli możliwe
```

### 8. Monitoruj connectivity do datasources

Konfiguruj health checks i alerty dla datasources:

```yaml
# Provisioning health check
jsonData:
  healthCheckInterval: 60s
```

Monitoruj metryki Grafany:
- `grafana_datasource_request_duration_seconds`
- `grafana_datasource_request_total`
- `grafana_datasource_response_size_bytes`

### 9. Używaj read-only users dla datasources

Grafana nie powinna mieć write access do datasources (z wyjątkiem alerting w Prometheus/Loki).

**PostgreSQL:**
```sql
CREATE ROLE grafana_ro WITH LOGIN PASSWORD 'secure_password';
GRANT CONNECT ON DATABASE metrics_db TO grafana_ro;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO grafana_ro;
ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO grafana_ro;
```

### 10. Segreguj datasources per environment

Używaj osobnych datasources dla dev, staging, prod:

```yaml
datasources:
  - name: Prometheus Dev
    uid: prometheus-dev
    url: http://prometheus.dev.internal:9090

  - name: Prometheus Staging
    uid: prometheus-staging
    url: http://prometheus.staging.internal:9090

  - name: Prometheus Production
    uid: prometheus-prod
    url: http://prometheus.prod.internal:9090
```

Umożliwia to:
- Testowanie dashboardów w dev bez wpływu na prod
- Eksport/import dashboardów między środowiskami (poprzez zmianę UID)

---

## Częste błędy i troubleshooting

### Problem 1: "Data source connected, but no labels received"

**Objawy:** Datasource testuje się pozytywnie, ale brak danych w Explore/dashboardach.

**Przyczyny:**
1. Datasource jest pusty (brak danych w Prometheus/Loki)
2. Time range jest poza zakresem dostępnych danych
3. Query syntax error

**Rozwiązanie:**
```bash
# Weryfikuj dane bezpośrednio w datasource
curl "http://prometheus.internal:9090/api/v1/label/__name__/values"
curl "http://loki.internal:3100/loki/api/v1/labels"
```

### Problem 2: "Request timeout"

**Objawy:** Query przekracza timeout i zwraca błąd.

**Przyczyny:**
1. Query jest zbyt ciężkie (duży time range, wiele serii)
2. Datasource jest przeciążony
3. Network latency

**Rozwiązanie:**
```yaml
# Zwiększ timeout w datasource config
jsonData:
  queryTimeout: 300s
  timeout: 120
```

Optymalizuj query:
- Zmniejsz time range
- Dodaj więcej filtrów (labels w PromQL, filters w SQL)
- Używaj agregacji (sum, avg) zamiast raw data

### Problem 3: "Unauthorized" / "403 Forbidden"

**Objawy:** Datasource nie może połączyć się z backendem.

**Przyczyny:**
1. Nieprawidłowe credentials
2. Expired token
3. IP whitelisting na datasource

**Rozwiązanie:**
```bash
# Testuj credentials manualnie
curl -H "Authorization: Bearer <token>" http://prometheus.internal:9090/api/v1/metadata

# Sprawdź logi Grafany
journalctl -u grafana-server | grep -i "auth\|unauthorized"
```

### Problem 4: "Bad Gateway" / "Connection refused"

**Objawy:** Grafana nie może połączyć się z datasource.

**Przyczyny:**
1. Datasource nie działa
2. Network connectivity issues
3. Firewall blokuje połączenia
4. Nieprawidłowy URL w konfiguracji

**Rozwiązanie:**
```bash
# Z hosta Grafany, testuj connectivity
docker exec grafana curl -v http://prometheus.internal:9090/api/v1/status/config

# Weryfikuj DNS resolution
docker exec grafana nslookup prometheus.internal

# Weryfikuj firewall/security groups
```

### Problem 5: "x509: certificate signed by unknown authority"

**Objawy:** TLS verification failure.

**Przyczyny:**
1. Self-signed certificate na datasource
2. Brak CA certificate w konfiguracji Grafany

**Rozwiązanie:**

**Option A: Dodaj CA cert (zalecane)**
```yaml
jsonData:
  tlsAuthWithCACert: true
secureJsonData:
  tlsCACert: |
    -----BEGIN CERTIFICATE-----
    <CA_CERTIFICATE>
    -----END CERTIFICATE-----
```

**Option B: Wyłącz verification (TYLKO dev/test)**
```yaml
jsonData:
  tlsSkipVerify: true  # NIEBEZPIECZNE w produkcji
```

### Problem 6: "Datasource provisioning not updating"

**Objawy:** Zmiany w provisioning YAML nie są stosowane.

**Przyczyny:**
1. Błędy składniowe w YAML
2. Datasource jest `editable: true` i został ręcznie zmieniony w UI
3. Grafana nie ma uprawnień do odczytu plików provisioning

**Rozwiązanie:**
```bash
# Sprawdź logi provisioning
journalctl -u grafana-server | grep provisioning

# Weryfikuj składnię YAML
yamllint /etc/grafana/provisioning/datasources/*.yml

# Sprawdź uprawnienia
ls -la /etc/grafana/provisioning/datasources/

# Force reload (restart Grafany)
systemctl restart grafana-server
```

---

## Zaawansowane tematy

### Query Inspector

Grafana oferuje Query Inspector do debugowania zapytań:

**Ścieżka:** Dashboard → Panel → Inspect → Query

**Dostępne informacje:**
- Raw query wysłane do datasource
- Response time
- Request size / Response size
- HTTP status code
- Raw response (JSON)

**Użycie:** Diagnozowanie slow queries, weryfikacja query correctness.

### Datasource HTTP Proxy

Grafana może routować zapytania przez HTTP proxy:

```ini
# grafana.ini
[http]
proxy = http://proxy.internal:3128
no_proxy = localhost,127.0.0.1,*.internal
```

**Użycie:** Dostęp do datasources w izolowanych sieciach przez corporate proxy.

### Derived Fields (Loki → Tempo)

Grafana może automatycznie ekstraktować trace IDs z logów i tworzyć linki do Tempo:

```yaml
# Loki datasource config
jsonData:
  derivedFields:
    - name: TraceID
      matcherRegex: "traceID=(\\w+)"
      url: "$${__value.raw}"
      datasourceUid: tempo-prod
```

**Efekt:** Kliknięcie trace ID w logu Loki otwiera trace w Tempo.

### Mixed Datasource

Grafana oferuje special datasource "Mixed" pozwalający na użycie wielu datasources w jednym panelu:

```json
{
  "datasource": {
    "type": "mixed"
  },
  "targets": [
    {
      "datasource": {"uid": "prometheus-prod"},
      "expr": "rate(http_requests[5m])"
    },
    {
      "datasource": {"uid": "loki-prod"},
      "expr": "{app=\"frontend\"} |= \"error\""
    }
  ]
}
```

**Użycie:** Korelacja metryk i logów w jednym panelu.

---

## Podsumowanie

Architektura integracji danych w Grafanie opiera się na pluginowalnym systemie datasources działającym w trybie proxy. Backend Grafany pośredniczy między użytkownikami a zewnętrznymi źródłami danych, zapewniając:

1. **Bezpieczeństwo:** Credentials są encrypted i nigdy nie eksponowane do przeglądarki.
2. **Kontrola dostępu:** RBAC na poziomie datasources i queries.
3. **Jednolity interface:** Spójna API niezależnie od różnic w datasources.
4. **Wydajność:** Query caching (Enterprise), incremental queries, connection pooling.
5. **Isolation:** Datasources mogą być w prywatnych sieciach.

**Kluczowe zasady produkcyjne:**
- Używaj provisioning dla datasources (Infrastructure as Code)
- Konfiguruj stable UIDs
- Przechowuj credentials w zmiennych środowiskowych
- Używaj TLS i read-only users
- Monitoruj connectivity i performance datasources
- Testuj datasources w środowisku testowym przed produkcją

**Następne kroki:**
- Konfiguracja pierwszych datasources (Prometheus, Loki)
- Tworzenie dashboardów z multiple datasources
- Implementacja query optimization
- Konfiguracja alertingu z datasources


