# Warsztat - monitorowanie logów systemowych i aplikacyjnych

Warsztat praktyczny obejmujący kompleksową konfigurację systemu monitoringu logów z wykorzystaniem Loki, Promtail i Grafany. Uczestnik skonfiguruje zbieranie logów systemowych i aplikacyjnych oraz zbuduje dashboardy do ich wizualizacji.

## Cel warsztatu

Po ukończeniu warsztatu uczestnik będzie potrafił:

- Zainstalować i skonfigurować Promtail do zbierania logów
- Skonfigurować zbieranie logów systemowych (syslog, journald)
- Skonfigurować zbieranie logów aplikacyjnych (nginx, Docker)
- Tworzyć zapytania LogQL do analizy logów
- Budować dashboardy w Grafanie
- Konfigurować alerty na podstawie logów

## Wymagania wstępne

- Zainstalowany Loki (zgodnie z materiałem "Instalacja i konfiguracja Lokiego")
- Zainstalowana Grafana z dodanym Data Source Loki
- System Ubuntu 24.04 LTS
- Uprawnienia sudo
- Zainstalowany serwer web nginx (zostanie zainstalowany w warsztacie)

---

## Część 1: Instalacja i konfiguracja Promtail

Promtail to agent odpowiedzialny za zbieranie logów i wysyłanie ich do Lokiego.

### Krok 1: Pobranie i instalacja Promtail

```bash
# Pobranie Promtail
cd /tmp
wget https://github.com/grafana/loki/releases/download/v2.9.3/promtail-linux-amd64.zip

# Rozpakowanie
unzip promtail-linux-amd64.zip

# Przeniesienie do /usr/local/bin
sudo mv promtail-linux-amd64 /usr/local/bin/promtail

# Nadanie uprawnień
sudo chmod +x /usr/local/bin/promtail

# Weryfikacja instalacji
promtail --version
```

Oczekiwany wynik:

```
promtail, version 2.9.3 (branch: HEAD, revision: e24f5ab7a2b)
```

### Krok 2: Utworzenie użytkownika systemowego

```bash
# Utworzenie użytkownika promtail
sudo useradd --system --no-create-home --shell /bin/false promtail

# Utworzenie katalogów
sudo mkdir -p /etc/promtail
sudo mkdir -p /var/lib/promtail

# Ustawienie właściciela
sudo chown -R promtail:promtail /etc/promtail
sudo chown -R promtail:promtail /var/lib/promtail
```

### Krok 3: Konfiguracja Promtail

Utworzenie pliku konfiguracyjnego:

```bash
sudo nano /etc/promtail/promtail-config.yaml
```

Podstawowa konfiguracja Promtail:

```yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0
  log_level: info

positions:
  filename: /var/lib/promtail/positions.yaml

clients:
  - url: http://localhost:3100/loki/api/v1/push

scrape_configs:
  # Zbieranie logów systemowych z journald
  - job_name: system
    journal:
      max_age: 12h
      labels:
        job: systemd-journal
        host: localhost
    relabel_configs:
      - source_labels: ['__journal__systemd_unit']
        target_label: 'unit'
```

**Wyjaśnienie sekcji:**

- **server**: Konfiguracja serwera HTTP Promtail dla metryk i health check.
- **positions**: Plik przechowujący pozycje odczytu w logach (checkpoint).
- **clients**: Lista serwerów Loki do wysyłania logów.
- **scrape_configs**: Konfiguracja źródeł logów do zbierania.

### Krok 4: Utworzenie usługi systemd

```bash
sudo nano /etc/systemd/system/promtail.service
```

Zawartość pliku usługi:

```ini
[Unit]
Description=Promtail Log Collector
Documentation=https://grafana.com/docs/loki/latest/clients/promtail/
After=network-online.target
Wants=network-online.target

[Service]
Type=simple
User=promtail
Group=promtail
ExecStart=/usr/local/bin/promtail -config.file=/etc/promtail/promtail-config.yaml
Restart=always
RestartSec=5
StandardOutput=journal
StandardError=journal
SyslogIdentifier=promtail

# Uprawnienia do odczytu logów
SupplementaryGroups=systemd-journal adm

[Install]
WantedBy=multi-user.target
```

**Uwaga:** `SupplementaryGroups=systemd-journal adm` zapewnia dostęp do logów systemowych.

### Krok 5: Uruchomienie Promtail

```bash
# Przeładowanie konfiguracji systemd
sudo systemctl daemon-reload

# Uruchomienie usługi
sudo systemctl start promtail

# Włączenie automatycznego startu
sudo systemctl enable promtail

# Sprawdzenie statusu
sudo systemctl status promtail
```

### Krok 6: Weryfikacja działania

```bash
# Sprawdzenie metryk Promtail
curl http://localhost:9080/metrics

# Sprawdzenie logów Promtail
sudo journalctl -u promtail -n 50

# Sprawdzenie czy logi trafiają do Lokiego
curl -G -s "http://localhost:3100/loki/api/v1/query" \
  --data-urlencode 'query={job="systemd-journal"}' \
  --data-urlencode 'limit=10' | jq
```

Jeśli widzisz logi w odpowiedzi, Promtail działa poprawnie.

---

## Część 2: Zbieranie logów systemowych

### Konfiguracja 1: Logi z journald (systemd)

Konfiguracja już dodana w podstawowym pliku `promtail-config.yaml`:

```yaml
scrape_configs:
  - job_name: system
    journal:
      max_age: 12h
      labels:
        job: systemd-journal
        host: localhost
    relabel_configs:
      - source_labels: ['__journal__systemd_unit']
        target_label: 'unit'
      - source_labels: ['__journal__hostname']
        target_label: 'hostname'
      - source_labels: ['__journal_priority_keyword']
        target_label: 'level'
```

**Testowanie w Grafana Explore:**

```logql
# Wszystkie logi systemowe
{job="systemd-journal"}

# Logi konkretnej usługi
{job="systemd-journal", unit="ssh.service"}

# Błędy systemowe
{job="systemd-journal", level="error"}

# Logi kernel
{job="systemd-journal", unit="kernel"}
```

### Konfiguracja 2: Logi z plików tekstowych

Dodanie konfiguracji dla logów z plików `/var/log`:

```bash
sudo nano /etc/promtail/promtail-config.yaml
```

Dodanie sekcji:

```yaml
scrape_configs:
  # Logi systemowe z journald (już istnieje)
  - job_name: system
    journal:
      max_age: 12h
      labels:
        job: systemd-journal
        host: localhost
    relabel_configs:
      - source_labels: ['__journal__systemd_unit']
        target_label: 'unit'

  # Logi z /var/log/syslog
  - job_name: syslog
    static_configs:
      - targets:
          - localhost
        labels:
          job: syslog
          host: localhost
          __path__: /var/log/syslog

  # Logi z /var/log/auth.log
  - job_name: auth
    static_configs:
      - targets:
          - localhost
        labels:
          job: auth
          host: localhost
          __path__: /var/log/auth.log
```

**Uprawnienia do plików logów:**

```bash
# Dodanie użytkownika promtail do grupy adm
sudo usermod -aG adm promtail

# Restart Promtail
sudo systemctl restart promtail
```

**Testowanie:**

```logql
# Logi syslog
{job="syslog"}

# Logi uwierzytelniania
{job="auth"}

# Nieudane logowania SSH
{job="auth"} |= "Failed password"
```

---

## Część 3: Zbieranie logów nginx

### Krok 1: Instalacja nginx

```bash
# Instalacja nginx
sudo apt update
sudo apt install -y nginx

# Uruchomienie nginx
sudo systemctl start nginx
sudo systemctl enable nginx

# Sprawdzenie statusu
sudo systemctl status nginx
```

### Krok 2: Konfiguracja zbierania logów nginx

Dodanie konfiguracji Promtail dla logów nginx:

```bash
sudo nano /etc/promtail/promtail-config.yaml
```

Dodanie sekcji:

```yaml
scrape_configs:
  # ... poprzednie konfiguracje ...

  # Nginx access log
  - job_name: nginx-access
    static_configs:
      - targets:
          - localhost
        labels:
          job: nginx
          type: access
          host: localhost
          __path__: /var/log/nginx/access.log

  # Nginx error log
  - job_name: nginx-error
    static_configs:
      - targets:
          - localhost
        labels:
          job: nginx
          type: error
          host: localhost
          __path__: /var/log/nginx/error.log
```

**Restart Promtail:**

```bash
sudo systemctl restart promtail
```

### Krok 3: Generowanie ruchu testowego

```bash
# Generowanie normalnych żądań
for i in {1..20}; do curl -s http://localhost/ > /dev/null; done

# Generowanie błędów 404
for i in {1..10}; do curl -s http://localhost/notfound > /dev/null; done

# Generowanie dużego ruchu
for i in {1..100}; do
  curl -s http://localhost/ > /dev/null &
done
wait
```

### Krok 4: Analiza logów nginx w Grafana Explore

```logql
# Wszystkie logi access
{job="nginx", type="access"}

# Błędy HTTP (4xx, 5xx)
{job="nginx", type="access"} |~ " (4|5)[0-9]{2} "

# Parsowanie logów nginx
{job="nginx", type="access"} 
| pattern `<ip> - - <_> "<method> <uri> <_>" <status> <size> "<_>" "<agent>"`

# Filtrowanie po kodzie statusu
{job="nginx", type="access"} 
| pattern `<ip> - - <_> "<method> <uri> <_>" <status> <size>`
| status >= 400

# Rate żądań HTTP
sum(rate({job="nginx", type="access"}[5m]))

# Rate błędów 4xx i 5xx
sum(rate({job="nginx"} |~ " (4|5)[0-9]{2} " [5m]))

# Top 10 najczęściej żądanych URI
topk(10, 
  sum by (uri) (
    count_over_time(
      {job="nginx"} 
      | pattern `<_> "<method> <uri> <_>" <_>`
      [1h]
    )
  )
)
```

---

## Część 4: Zbieranie logów Docker

### Krok 1: Instalacja Docker (jeśli nie zainstalowany)

```bash
# Instalacja Docker
sudo apt install -y docker.io

# Dodanie użytkownika do grupy docker
sudo usermod -aG docker $USER

# Restart sesji lub reboot
```

### Krok 2: Uruchomienie testowego kontenera

```bash
# Uruchomienie testowego kontenera nginx
docker run -d \
  --name test-nginx \
  --label "logging=enabled" \
  -p 8080:80 \
  nginx:alpine

# Sprawdzenie logów
docker logs test-nginx
```

### Krok 3: Konfiguracja Promtail dla Docker

Dodanie konfiguracji:

```bash
sudo nano /etc/promtail/promtail-config.yaml
```

Dodanie sekcji:

```yaml
scrape_configs:
  # ... poprzednie konfiguracje ...

  # Docker containers
  - job_name: docker
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
    relabel_configs:
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.*)'
        target_label: 'container'
      - source_labels: ['__meta_docker_container_log_stream']
        target_label: 'stream'
      - source_labels: ['__meta_docker_container_label_logging']
        regex: 'enabled'
        action: keep
```

**Uprawnienia do Docker socket:**

```bash
# Dodanie użytkownika promtail do grupy docker
sudo usermod -aG docker promtail

# Restart Promtail
sudo systemctl restart promtail
```

### Krok 4: Testowanie logów Docker

```bash
# Generowanie logów
for i in {1..50}; do
  curl -s http://localhost:8080/ > /dev/null
done
```

**Zapytania w Grafana Explore:**

```logql
# Wszystkie logi z kontenerów Docker
{job="docker"}

# Logi konkretnego kontenera
{job="docker", container="test-nginx"}

# Rate logów z kontenerów
sum by (container) (rate({job="docker"}[5m]))
```

---

## Część 5: Monitorowanie aplikacji (JSON logs)

### Krok 1: Utworzenie aplikacji testowej

Prosta aplikacja Python logująca w formacie JSON:

```bash
# Instalacja Python
sudo apt install -y python3 python3-pip

# Utworzenie katalogu aplikacji
mkdir -p ~/test-app
cd ~/test-app

# Utworzenie aplikacji
cat > app.py << 'EOF'
import json
import logging
import time
import random
from datetime import datetime

# Konfiguracja logowania JSON
class JsonFormatter(logging.Formatter):
    def format(self, record):
        log_data = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record.levelname,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
        }
        if hasattr(record, 'user_id'):
            log_data['user_id'] = record.user_id
        if hasattr(record, 'duration'):
            log_data['duration'] = record.duration
        return json.dumps(log_data)

logger = logging.getLogger()
logger.setLevel(logging.INFO)

handler = logging.FileHandler('/tmp/app.log')
handler.setFormatter(JsonFormatter())
logger.addHandler(handler)

print("Application started. Logs are written to /tmp/app.log")

while True:
    # Symulacja różnych zdarzeń
    event = random.choice(['request', 'error', 'warning', 'info'])
    
    if event == 'request':
        user_id = random.randint(1, 100)
        duration = random.randint(10, 500)
        extra = {'user_id': user_id, 'duration': duration}
        logger.info(f"API request processed", extra=extra)
    elif event == 'error':
        logger.error("Database connection failed")
    elif event == 'warning':
        logger.warning("High memory usage detected")
    else:
        logger.info("Health check OK")
    
    time.sleep(random.randint(1, 5))
EOF
```

### Krok 2: Uruchomienie aplikacji

```bash
# Uruchomienie aplikacji w tle
nohup python3 app.py &

# Sprawdzenie logów
tail -f /tmp/app.log
```

### Krok 3: Konfiguracja Promtail dla JSON logs

```bash
sudo nano /etc/promtail/promtail-config.yaml
```

Dodanie sekcji:

```yaml
scrape_configs:
  # ... poprzednie konfiguracje ...

  # Application JSON logs
  - job_name: app
    static_configs:
      - targets:
          - localhost
        labels:
          job: test-app
          environment: dev
          __path__: /tmp/app.log
    pipeline_stages:
      - json:
          expressions:
            timestamp: timestamp
            level: level
            message: message
            module: module
      - labels:
          level:
          module:
      - timestamp:
          source: timestamp
          format: RFC3339Nano
```

**Wyjaśnienie pipeline_stages:**

- **json**: Parsowanie logów JSON i ekstrakcja pól.
- **labels**: Konwersja pól na etykiety.
- **timestamp**: Użycie timestampa z logu zamiast czasu odbioru.

**Restart Promtail:**

```bash
sudo systemctl restart promtail
```

### Krok 4: Analiza JSON logs

```logql
# Wszystkie logi aplikacji
{job="test-app"}

# Parsowanie JSON
{job="test-app"} | json

# Filtrowanie po poziomie
{job="test-app"} | json | level="error"

# Filtrowanie po czasie trwania
{job="test-app"} | json | duration > 200

# Rate błędów
sum(rate({job="test-app", level="error"}[5m]))

# Średni czas przetwarzania
avg_over_time(
  {job="test-app"} 
  | json 
  | unwrap duration [5m]
)

# Top user_id z największą liczbą żądań
topk(10, 
  sum by (user_id) (
    count_over_time(
      {job="test-app"} 
      | json 
      | user_id != ""
      [1h]
    )
  )
)
```

---

## Część 6: Budowa dashboardu monitoringu

### Dashboard: System and Application Monitoring

#### Panel 1: System Health - Errors

**Typ:** Stat

**Zapytanie:**

```logql
count_over_time({job="systemd-journal", level="error"}[1h])
```

**Konfiguracja:**
- Title: "System Errors (1h)"
- Thresholds: 0-10 (green), 10-50 (yellow), 50+ (red)

#### Panel 2: Nginx Request Rate

**Typ:** Time series

**Zapytanie:**

```logql
sum(rate({job="nginx", type="access"}[5m]))
```

**Konfiguracja:**
- Title: "Nginx Requests/sec"
- Unit: reqps

#### Panel 3: HTTP Status Codes

**Typ:** Time series (stacked)

**Zapytania:**

```logql
# 2xx
sum(rate({job="nginx"} |~ " 2[0-9]{2} " [5m]))

# 4xx
sum(rate({job="nginx"} |~ " 4[0-9]{2} " [5m]))

# 5xx
sum(rate({job="nginx"} |~ " 5[0-9]{2} " [5m]))
```

#### Panel 4: Application Errors

**Typ:** Time series

**Zapytanie:**

```logql
sum by (level) (rate({job="test-app"}[5m]))
```

#### Panel 5: Docker Containers Logs

**Typ:** Logs

**Zapytanie:**

```logql
{job="docker"}
```

#### Panel 6: Recent System Logs

**Typ:** Logs

**Zapytanie:**

```logql
{job="systemd-journal"}
```

**Konfiguracja:**
- Order: Newest first
- Lines: 50

### Zapisanie dashboardu

1. Kliknij **Save dashboard** (ikona dyskietki)
2. Podaj nazwę: "System and Application Monitoring"
3. Wybierz folder lub zostaw "General"
4. Kliknij **Save**

---

## Część 7: Konfiguracja alertów

### Alert 1: Wysoka liczba błędów systemowych

#### Krok 1: Utworzenie panelu z metryką

**Typ:** Time series

**Zapytanie:**

```logql
sum(rate({job="systemd-journal", level="error"}[5m]))
```

#### Krok 2: Konfiguracja alertu

1. W edycji panelu przejdź do zakładki **Alert**
2. Kliknij **Create alert rule from this panel**
3. Skonfiguruj:

**Alert rule:**
- Name: "High System Error Rate"
- Evaluate: Every 1m for 5m
- Condition: WHEN last() OF query(A) IS ABOVE 5

**Annotations:**
- Summary: "High number of system errors detected"
- Description: "{{ $value }} errors/sec in the last 5 minutes"

### Alert 2: Wysokie wykorzystanie błędów HTTP 5xx

**Zapytanie:**

```logql
sum(rate({job="nginx"} |~ " 5[0-9]{2} " [5m]))
```

**Warunek:**
- WHEN last() OF query(A) IS ABOVE 1

### Alert 3: Brak logów (heartbeat)

**Zapytanie:**

```logql
count_over_time({job="test-app"}[5m])
```

**Warunek:**
- WHEN last() OF query(A) IS BELOW 10

### Konfiguracja Contact Point

1. Przejdź do **Alerting** → **Contact points**
2. Kliknij **New contact point**
3. Wybierz typ (Email, Slack, Webhook)
4. Skonfiguruj dane kontaktowe
5. Zapisz

---

## Część 8: Zadania praktyczne

### Zadanie 1: Analiza nieudanych prób logowania SSH

**Cel:** Znaleźć IP adresy z największą liczbą nieudanych prób logowania.

**Kroki:**

1. Znajdź logi uwierzytelniania:
```logql
{job="auth"} |= "Failed password"
```

2. Wyekstrahuj IP adres używając parsera pattern:
```logql
{job="auth"} |= "Failed password" 
| pattern `<_> Failed password for <user> from <ip> port <_>`
```

3. Agreguj i znajdź top 10 IP:
```logql
topk(10, 
  sum by (ip) (
    count_over_time(
      {job="auth"} |= "Failed password" 
      | pattern `<_> Failed password for <user> from <ip> port <_>`
      [24h]
    )
  )
)
```

4. Utwórz panel typu Table z wynikami

### Zadanie 2: Monitoring czasu odpowiedzi nginx

**Cel:** Monitorować czas odpowiedzi nginx i wykrywać powolne żądania.

**Kroki:**

1. Skonfiguruj nginx do logowania czasu odpowiedzi:

```bash
sudo nano /etc/nginx/nginx.conf
```

Dodaj w sekcji `http`:

```nginx
log_format timed_combined '$remote_addr - $remote_user [$time_local] '
                         '"$request" $status $body_bytes_sent '
                         '"$http_referer" "$http_user_agent" '
                         '$request_time';

access_log /var/log/nginx/access.log timed_combined;
```

```bash
# Restart nginx
sudo systemctl reload nginx
```

2. Zapytanie LogQL do parsowania czasu:

```logql
{job="nginx", type="access"} 
| pattern `<ip> - - <_> "<method> <uri> <_>" <status> <size> "<_>" "<_>" <response_time>`
| unwrap response_time
```

3. Średni czas odpowiedzi:

```logql
avg_over_time(
  {job="nginx"} 
  | pattern `<_> <response_time>`
  | unwrap response_time [5m]
)
```

4. P95 czas odpowiedzi:

```logql
quantile_over_time(0.95, 
  {job="nginx"} 
  | pattern `<_> <response_time>`
  | unwrap response_time [5m]
)
```

### Zadanie 3: Dashboard z zmienną dla środowiska

**Cel:** Utworzyć dashboard z możliwością przełączania między środowiskami.

**Kroki:**

1. Dodaj etykietę `environment` w konfiguracji Promtail

2. Utwórz zmienną w dashboardzie:
   - Name: `environment`
   - Type: Query
   - Query: `label_values(environment)`

3. Użyj zmiennej w zapytaniach:

```logql
{environment="$environment"}
```

4. Dodaj panele korzystające z zmiennej

### Zadanie 4: Korelacja metryk i logów

**Cel:** Powiązać metryki z Prometheusa z logami z Lokiego.

**Wymagania:**
- Zainstalowany Prometheus
- Node Exporter

**Kroki:**

1. Panel z metryką CPU (Prometheus):

```promql
100 - (avg(rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
```

2. Panel z logami systemowymi (Loki):

```logql
{job="systemd-journal"}
```

3. Skonfiguruj Data Link w panelu z metryką:
   - Title: "View logs"
   - URL: `/explore?left={"datasource":"Loki","queries":[{"expr":"{job=\"systemd-journal\"}"}],"range":{"from":"${__from}","to":"${__to}"}}`

4. Kliknij w punkt na wykresie CPU → automatyczne przekierowanie do logów z tego czasu

---

## Część 9: Troubleshooting

### Problem 1: Promtail nie zbiera logów

**Diagnostyka:**

```bash
# Sprawdzenie statusu Promtail
sudo systemctl status promtail

# Przegląd logów Promtail
sudo journalctl -u promtail -n 100 --no-pager

# Sprawdzenie uprawnień
ls -la /var/log/nginx/
groups promtail

# Sprawdzenie konfiguracji
promtail -config.file=/etc/promtail/promtail-config.yaml -dry-run
```

**Rozwiązania:**
- Sprawdź uprawnienia do plików logów
- Sprawdź składnię pliku konfiguracyjnego
- Sprawdź czy ścieżki do plików są poprawne
- Dodaj użytkownika promtail do odpowiednich grup

### Problem 2: Brak logów w Grafanie

**Diagnostyka:**

```bash
# Sprawdzenie czy Loki otrzymuje logi
curl -s "http://localhost:3100/loki/api/v1/labels" | jq

# Lista wartości dla job
curl -s "http://localhost:3100/loki/api/v1/label/job/values" | jq

# Testowe zapytanie
curl -G -s "http://localhost:3100/loki/api/v1/query" \
  --data-urlencode 'query={job="nginx"}' \
  --data-urlencode 'limit=10'
```

### Problem 3: Wysokie zużycie zasobów przez Promtail

**Optymalizacja:**

1. Ogranicz liczbę zbieranych logów:

```yaml
scrape_configs:
  - job_name: nginx
    static_configs:
      - targets:
          - localhost
        labels:
          job: nginx
          __path__: /var/log/nginx/access.log
    # Pomijanie logów healthcheck
    pipeline_stages:
      - match:
          selector: '{job="nginx"}'
          stages:
            - drop:
                expression: ".*healthcheck.*"
```

2. Zwiększ interwał wysyłania:

```yaml
clients:
  - url: http://localhost:3100/loki/api/v1/push
    batchwait: 5s
    batchsize: 1048576  # 1MB
```

---

## Część 10: Podsumowanie warsztatu

### Zrealizowane cele

✅ Instalacja i konfiguracja Promtail
✅ Zbieranie logów systemowych (journald, syslog)
✅ Zbieranie logów aplikacyjnych (nginx, Docker, JSON)
✅ Tworzenie zapytań LogQL
✅ Budowa dashboardów w Grafanie
✅ Konfiguracja alertów

### Architektura systemu

```
┌─────────────────┐
│  System Logs    │───┐
│  (journald)     │   │
└─────────────────┘   │
                      │
┌─────────────────┐   │    ┌──────────┐    ┌──────────┐
│  Nginx Logs     │───┼───▶│ Promtail │───▶│   Loki   │
│  (access/error) │   │    └──────────┘    └──────────┘
└─────────────────┘   │                         │
                      │                         │
┌─────────────────┐   │                         ▼
│  Docker Logs    │───┘                    ┌──────────┐
│  (containers)   │                        │ Grafana  │
└─────────────────┘                        │          │
                                           │ Explore  │
┌─────────────────┐                        │Dashboard │
│  App Logs       │──────────────────────▶│ Alerts   │
│  (JSON)         │    (File monitoring)  └──────────┘
└─────────────────┘
```

### Kluczowe komendy

**Zarządzanie Promtail:**

```bash
# Status
sudo systemctl status promtail

# Restart
sudo systemctl restart promtail

# Logi
sudo journalctl -u promtail -f

# Weryfikacja konfiguracji
promtail -config.file=/etc/promtail/promtail-config.yaml -dry-run
```

**Testowanie logów:**

```bash
# Lista etykiet
curl -s http://localhost:3100/loki/api/v1/labels | jq

# Wartości job
curl -s http://localhost:3100/loki/api/v1/label/job/values | jq

# Zapytanie o logi
curl -G -s "http://localhost:3100/loki/api/v1/query" \
  --data-urlencode 'query={job="nginx"}' \
  --data-urlencode 'limit=10' | jq
```

### Najlepsze praktyki

1. **Etykietowanie**
   - Używaj niskokardinanych etykiet
   - Nie używaj wartości dynamicznych jako etykiet
   - Ogranicz liczbę etykiet (5-10 na stream)

2. **Parsowanie logów**
   - Parsuj logi w pipeline_stages Promtail zamiast w zapytaniach
   - Używaj JSON dla nowych aplikacji
   - Standaryzuj format logów

3. **Wydajność**
   - Konfiguruj retencję w Lokiego
   - Monitoruj zużycie zasobów
   - Optymalizuj zapytania LogQL

4. **Bezpieczeństwo**
   - Ogranicz dostęp do Lokiego przez firewall
   - Używaj autentykacji w środowisku produkcyjnym
   - Szyfruj połączenia (TLS)

### Dalsze kroki

- Eksploracja zaawansowanych funkcji LogQL
- Konfiguracja Loki w trybie rozproszonego klastra
- Integracja z systemami alertowania (PagerDuty, OpsGenie)
- Konfiguracja długoterminowego przechowywania (S3, GCS)
- Implementacja multi-tenancy
