# Budowa dashboardów opartych o logi

Dashboardy oparte o logi w Grafanie służą do wizualizacji i analizy danych z Lokiego. Poniżej przedstawiono praktyczne przykłady kompletnych dashboardów dla różnych scenariuszy monitorowania logów.

**Uwaga:** Podstawy tworzenia dashboardów i paneli w Grafanie omówiono w [Moduł 6 - Dashboard](../Moduł%206%20-%20Dashboard/). Niniejszy materiał koncentruje się na zastosowaniu LogQL i specyficznych wzorcach dla log management.

---

## Dashboard 1: Nginx Access Logs Analysis

Kompletny dashboard do analizy logów dostępowych serwera nginx.

### Panel 1: Total Requests (ostatnia godzina)

**Typ:** Stat  
**Umiejscowienie:** Rząd 1, Kolumna 1

**Zapytanie LogQL:**

```logql
sum(count_over_time({job="nginx", type="access"}[1h]))
```

**Konfiguracja panelu:**
- Unit: `short`
- Color mode: `Background`
- Text mode: `Value and name`
- Thresholds: 
  - 0-1000: Green
  - 1000-5000: Yellow  
  - 5000+: Red

### Panel 2: Error Rate (4xx + 5xx)

**Typ:** Stat  
**Umiejscowienie:** Rząd 1, Kolumna 2

**Zapytanie LogQL:**

```logql
sum(count_over_time({job="nginx", type="access"} |~ " (4|5)[0-9]{2} " [1h]))
```

**Konfiguracja panelu:**
- Unit: `short`
- Color mode: `Background`
- Thresholds:
  - 0-10: Green
  - 10-50: Yellow
  - 50+: Red

### Panel 3: Requests per Second

**Typ:** Time series  
**Umiejscowienie:** Rząd 2, Full width

**Zapytanie LogQL:**

```logql
sum(rate({job="nginx", type="access"}[5m]))
```

**Konfiguracja panelu:**
- Unit: `reqps` (requests per second)
- Line width: 2
- Fill opacity: 20
- Gradient mode: None

### Panel 4: HTTP Status Codes Distribution

**Typ:** Time series (stacked)  
**Umiejscowienie:** Rząd 3, Full width

**Zapytania LogQL:**

```logql
# Query A: 2xx Success
sum(rate({job="nginx"} | pattern `<_> "<_>" <status> <_>` | status >= 200 and status < 300 [5m]))

# Query B: 3xx Redirect  
sum(rate({job="nginx"} | pattern `<_> "<_>" <status> <_>` | status >= 300 and status < 400 [5m]))

# Query C: 4xx Client Error
sum(rate({job="nginx"} | pattern `<_> "<_>" <status> <_>` | status >= 400 and status < 500 [5m]))

# Query D: 5xx Server Error
sum(rate({job="nginx"} | pattern `<_> "<_>" <status> <_>` | status >= 500 [5m]))
```

**Konfiguracja panelu:**
- Stacking: Normal
- Unit: `reqps`
- Legend: Bottom
- Series overrides:
  - 2xx: Green
  - 3xx: Blue
  - 4xx: Orange
  - 5xx: Red

### Panel 5: Top 10 Requested URIs

**Typ:** Table  
**Umiejscowienie:** Rząd 4, Lewa połowa

**Zapytanie LogQL:**

```logql
topk(10, 
  sum by (uri) (
    count_over_time(
      {job="nginx"} 
      | pattern `<_> "<method> <uri> <_>" <_>`
      [1h]
    )
  )
)
```

**Konfiguracja panelu:**
- Columns: URI, Count
- Sort by: Count (descending)
- Show header: Yes

### Panel 6: Top 10 Client IPs

**Typ:** Table  
**Umiejscowienie:** Rząd 4, Prawa połowa

**Zapytanie LogQL:**

```logql
topk(10, 
  sum by (ip) (
    count_over_time(
      {job="nginx"} 
      | pattern `<ip> <_>`
      [1h]
    )
  )
)
```

### Panel 7: Response Time Percentiles (jeśli logowane)

**Typ:** Time series  
**Umiejscowienie:** Rząd 5, Full width

**Zapytania LogQL:**

```logql
# p50
quantile_over_time(0.5, 
  {job="nginx"} 
  | pattern `<_> <_> <_> <response_time>`
  | unwrap response_time [5m]
)

# p95
quantile_over_time(0.95, 
  {job="nginx"} 
  | pattern `<_> <_> <_> <response_time>`
  | unwrap response_time [5m]
)

# p99
quantile_over_time(0.99, 
  {job="nginx"} 
  | pattern `<_> <_> <_> <response_time>`
  | unwrap response_time [5m]
)
```

**Konfiguracja panelu:**
- Unit: `seconds (s)`
- Legend values: Last
- Lines: p50, p95, p99

### Panel 8: Recent Logs (Live Tail)

**Typ:** Logs  
**Umiejscowienie:** Rząd 6, Full width

**Zapytanie LogQL:**

```logql
{job="nginx", type="access"}
```

**Konfiguracja panelu:**
- Order: Newest first
- Max lines: 50
- Deduplication: None
- Enable log details: Yes

---

## Dashboard 2: System Logs Security Monitoring

Dashboard do monitorowania bezpieczeństwa na podstawie logów systemowych.

### Panel 1: Failed SSH Login Attempts

**Typ:** Stat  
**Zapytanie LogQL:**

```logql
sum(count_over_time({job="auth"} |= "Failed password" [1h]))
```

### Panel 2: Failed SSH Attempts Over Time

**Typ:** Time series  
**Zapytanie LogQL:**

```logql
sum(rate({job="auth"} |= "Failed password" [5m]))
```

### Panel 3: Top 10 Attacking IPs

**Typ:** Bar gauge (Horizontal)  
**Zapytanie LogQL:**

```logql
topk(10, 
  sum by (ip) (
    count_over_time(
      {job="auth"} |= "Failed password" 
      | pattern `<_> from <ip> port <_>`
      [24h]
    )
  )
)
```

**Konfiguracja panelu:**
- Orientation: Horizontal
- Display mode: Gradient
- Color: Red (single color)

### Panel 4: Successful SSH Logins

**Typ:** Table  
**Zapytanie LogQL:**

```logql
{job="auth"} |= "Accepted password" 
| pattern `Accepted password for <user> from <ip> port <_>`
```

### Panel 5: Sudo Commands Executed

**Typ:** Logs  
**Zapytanie LogQL:**

```logql
{job="syslog"} |= "sudo" |= "COMMAND"
```

### Panel 6: System Errors and Warnings

**Typ:** Time series (stacked)  
**Zapytania LogQL:**

```logql
# Errors
sum(rate({job="syslog"} |~ "error|ERROR|err" [5m]))

# Warnings
sum(rate({job="syslog"} |~ "warning|WARNING|warn" [5m]))
```

---

## Dashboard 3: Application Logs (JSON Format)

Dashboard dla aplikacji logującej w formacie JSON.

### Panel 1: Error Rate by Service

**Typ:** Time series  
**Zapytanie LogQL:**

```logql
sum by (service) (
  rate(
    {app="myapp"} 
    | json 
    | level="error"
    [5m]
  )
)
```

**Konfiguracja:**
- Stack: Off (osobne linie dla każdego serwisu)
- Legend placement: Right
- Connect null values: No

### Panel 2: Request Duration p95 by Endpoint

**Typ:** Time series  
**Zapytanie LogQL:**

```logql
quantile_over_time(0.95,
  {app="myapp"} 
  | json 
  | unwrap duration 
  | __error__="" [5m]
) by (endpoint)
```

**Konfiguracja:**
- Unit: `milliseconds (ms)`
- Legend: Show percentile values

### Panel 3: Error Messages Breakdown

**Typ:** Pie chart  
**Zapytanie LogQL:**

```logql
sum by (error_type) (
  count_over_time(
    {app="myapp"} 
    | json 
    | level="error"
    [1h]
  )
)
```

### Panel 4: Log Levels Distribution

**Typ:** Bar chart (stacked)  
**Zapytania LogQL:**

```logql
# Debug
sum(rate({app="myapp"} | json | level="debug" [5m]))

# Info
sum(rate({app="myapp"} | json | level="info" [5m]))

# Warning  
sum(rate({app="myapp"} | json | level="warning" [5m]))

# Error
sum(rate({app="myapp"} | json | level="error" [5m]))
```

### Panel 5: Top Error Messages

**Typ:** Table  
**Zapytanie LogQL:**

```logql
topk(20, 
  sum by (message) (
    count_over_time(
      {app="myapp"} 
      | json 
      | level="error"
      [1h]
    )
  )
)
```

**Konfiguracja:**
- Sort: Value (descending)
- Table columns: Message (70%), Count (30%)

### Panel 6: Trace ID Correlation

**Typ:** Logs  
**Zapytanie LogQL:**

```logql
{app="myapp"} 
| json 
| trace_id="$trace_id"
```

**Uwaga:** Wymaga zmiennej `$trace_id` w dashboardzie.

---

## Dashboard 4: Docker Container Logs

Dashboard do monitorowania logów kontenerów Docker.

### Panel 1: Containers Log Rate

**Typ:** Time series  
**Zapytanie LogQL:**

```logql
sum by (container_name) (
  rate({job="docker"}[5m])
)
```

### Panel 2: Container Errors

**Typ:** Stat (Multiple)  
**Zapytanie LogQL:**

```logql
sum by (container_name) (
  count_over_time(
    {job="docker"} |~ "error|ERROR|exception"
    [1h]
  )
)
```

**Konfiguracja:**
- Repeat by variable: `$container`
- Layout: Auto

### Panel 3: Container Logs

**Typ:** Logs  
**Zapytanie LogQL:**

```logql
{job="docker", container_name=~"$container"}
```

### Panel 4: Container Restarts (z logów)

**Typ:** Table  
**Zapytanie LogQL:**

```logql
sum by (container_name) (
  count_over_time(
    {job="docker"} |= "Container started"
    [24h]
  )
)
```

---

## Dashboard 5: Multi-Source Log Correlation

Dashboard korelujący logi z wielu źródeł.

### Panel 1: All Errors Across Systems

**Typ:** Time series (stacked)  
**Zapytania LogQL:**

```logql
# Nginx errors
sum(rate({job="nginx"} |~ "error" [5m]))

# Application errors
sum(rate({app="myapp"} | json | level="error" [5m]))

# System errors
sum(rate({job="syslog"} |~ "error|ERROR" [5m]))
```

**Konfiguracja:**
- Stacking: Normal
- Legend: System, Application, Nginx
- Colors: Red shades

### Panel 2: Error Timeline by Source

**Typ:** Status history  
**Zapytania LogQL:**

```logql
# Nginx status
count_over_time({job="nginx"} |~ "error" [1m]) > 0

# App status
count_over_time({app="myapp"} | json | level="error" [1m]) > 0

# System status
count_over_time({job="syslog"} |~ "error" [1m]) > 0
```

### Panel 3: Combined Logs Search

**Typ:** Logs  
**Zapytanie LogQL:**

```logql
{job=~"nginx|syslog"} |~ "$search_query"
or
{app="myapp"} | json | message |~ "$search_query"
```

**Uwaga:** Wymaga zmiennej `$search_query`.

---

## Zmienne dla dashboardów logów

### Zmienna 1: Time Interval

```
Name: interval
Type: Interval
Values: 1m,5m,10m,30m,1h,6h,12h,24h
Auto: Yes
```

**Użycie:**
```logql
rate({job="nginx"}[$interval])
```

### Zmienna 2: Container Name

```
Name: container
Type: Query
Data source: Loki
Query: label_values({job="docker"}, container_name)
Multi-value: Yes
Include All: Yes
```

**Użycie:**
```logql
{job="docker", container_name=~"$container"}
```

### Zmienna 3: Log Level

```
Name: level
Type: Custom
Values: debug,info,warning,error,critical
Multi-value: Yes
Include All: Yes
```

**Użycie:**
```logql
{app="myapp"} | json | level=~"$level"
```

### Zmienna 4: Environment

```
Name: environment
Type: Query
Data source: Loki
Query: label_values(environment)
```

**Użycie:**
```logql
{environment="$environment"}
```

---

## Adnotacje dla dashboardów logów

### Deployment Events

**Data source:** Loki  
**Query:**

```logql
{job="deployment"} | json | event="deployment_started"
```

**Configuration:**
- Title field: `version`
- Text field: `message`
- Tags: `environment`
- Color: Blue

### System Reboots

**Query:**

```logql
{job="syslog"} |= "system boot"
```

**Configuration:**
- Title: "System Reboot"
- Color: Orange

### Application Errors Spike

**Query:**

```logql
sum(rate({app="myapp"} | json | level="error" [5m])) > 10
```

**Configuration:**
- Title: "Error Spike"
- Color: Red

---

## Przykładowe zapytania LogQL dla dashboardów

### Analiza wydajności

```logql
# Średni czas odpowiedzi
avg_over_time(
  {job="nginx"} 
  | pattern `<_> <response_time>`
  | unwrap response_time [5m]
)

# Liczba powolnych requestów (>1s)
sum(
  count_over_time(
    {job="nginx"} 
    | pattern `<_> <response_time>`
    | unwrap response_time > 1.0 [5m]
  )
)
```

### Analiza błędów

```logql
# Rate błędów z grupowaniem po typie
sum by (error_type) (
  rate(
    {app="myapp"} 
    | json 
    | level="error"
    [5m]
  )
)

# Unikalne komunikaty błędów
count by (message) (
  count_over_time(
    {app="myapp"} 
    | json 
    | level="error"
    [1h]
  )
)
```

### Analiza ruchu

```logql
# Requests z podziałem na metody HTTP
sum by (method) (
  rate(
    {job="nginx"} 
    | pattern `<_> "<method> <_>" <_>`
    [5m]
  )
)

# Top użytkownicy API (po user_id)
topk(10,
  sum by (user_id) (
    count_over_time(
      {app="api"} 
      | json 
      [1h]
    )
  )
)
```

### Analiza bezpieczeństwa

```logql
# Nieudane próby logowania z IP
sum by (ip) (
  count_over_time(
    {job="auth"} |= "Failed password" 
    | pattern `from <ip> port`
    [1h]
  )
)

# Podejrzane skanowania portów
count_over_time(
  {job="firewall"} |= "DENY" 
  | pattern `SRC=<src_ip> DST=<dst_ip> PROTO=<proto> DPT=<port>`
  | port < 1024
  [1h]
)
```

---

## Export dashboardów

### Eksport do JSON

```bash
# Export przez API
curl -H "Authorization: Bearer <API_KEY>" \
  "http://localhost:3000/api/dashboards/uid/<UID>" \
  | jq '.dashboard' > dashboard-loki-nginx.json
```

### Import dashboardu

1. W Grafanie: **Dashboards** → **Import**
2. Upload JSON file lub wklej JSON
3. Wybierz Data Source: **Loki**
4. Kliknij **Import**

---

## Gotowe dashboardy dla Lokiego

### Grafana.com Dashboard IDs

**14055** - Loki Stack Monitoring  
**13639** - Nginx Logs  
**12611** - System Logs (journald)  
**13407** - Docker Container Logs

**Import:**
```
Dashboards → Import → Load by ID
```

---

## Podsumowanie

Dashboardy oparte o logi wymagają:

1. **Doboru odpowiednich zapytań LogQL** - metryczne dla wykresów, log queries dla tabel
2. **Właściwego parsowania logów** - pattern, json, logfmt, regex
3. **Agregacji danych** - sum, count, topk, quantile dla wizualizacji trendów
4. **Korelacji** - łączenie logów z różnych źródeł
5. **Zmiennych** - dynamiczne filtrowanie po kontenerach, środowiskach, poziomach logów

**Kluczowe typy paneli dla logów:**
- **Logs** - surowe logi, debugging
- **Time series** - trendy, rate queries
- **Stat** - liczniki błędów, suma requestów
- **Table** - top N, agregacje wielowymiarowe
- **Bar gauge** - porównania między źródłami

**Następny temat:** [Warsztat - monitorowanie logów systemowych i aplikacyjnych](5.%20Warsztat%20-%20monitorowanie%20logów%20systemowych%20i%20aplikacyjnych.md)


### 1. Logs panel

Dedykowany panel do wyświetlania surowych logów.

**Zastosowanie:**
- Przeglądanie logów w czasie rzeczywistym
- Debugowanie problemów
- Analiza szczegółów logów

**Konfiguracja:**
- Data Source: Loki
- Wyświetlanie: Lista logów z timestampami
- Kolorowanie: Automatyczne kolorowanie poziomów logów
- Wrap: Zawijanie długich linii

### 2. Time series

Wykres liniowy do wizualizacji metryk z logów.

**Zastosowanie:**
- Monitorowanie trendów
- Szybkość logów (rate)
- Liczba wystąpień błędów

**Przykład zapytania:**

```logql
sum(rate({job="nginx"} |= "error" [5m]))
```

### 3. Stat

Panel do wyświetlania pojedynczej wartości lub statystyki.

**Zastosowanie:**
- Liczba błędów
- Suma logów w okresie
- Ostatnia wartość

**Przykład zapytania:**

```logql
count_over_time({job="nginx"} |= "error" [1h])
```

### 4. Bar gauge

Wizualizacja wartości w formie pasków poziomych.

**Zastosowanie:**
- Top N hostów z największą liczbą logów
- Porównanie różnych aplikacji

**Przykład zapytania:**

```logql
topk(10, sum by (host) (rate({job="nginx"}[5m])))
```

### 5. Table

Tabela z danymi w formacie tabelarycznym.

**Zastosowanie:**
- Lista błędów z detalami
- Agregacje z wieloma wymiarami

**Przykład zapytania:**

```logql
sum by (host, level) (count_over_time({job="app"}[1h]))
```

### 6. Pie chart

Wykres kołowy do wizualizacji proporcji.

**Zastosowanie:**
- Podział logów według poziomów (info, warn, error)
- Rozkład żądań HTTP według kodów statusu

**Przykład zapytania:**

```logql
sum by (level) (count_over_time({job="app"}[1h]))
```

---

## Dashboard: Monitoring logów systemowych

Przykład dashboardu do monitorowania logów systemowych z syslog.

### Panel 1: Live system logs

**Typ panelu:** Logs

**Zapytanie:**

```logql
{job="syslog"}
```

**Konfiguracja:**
- **Options** → **Show time**: Włączone
- **Options** → **Wrap lines**: Włączone
- **Options** → **Deduplication**: None
- **Options** → **Order**: Newest first

### Panel 2: Logs rate (logs per second)

**Typ panelu:** Time series

**Zapytanie:**

```logql
sum(rate({job="syslog"}[5m]))
```

**Konfiguracja:**
- **Panel options** → **Title**: "Logs per second"
- **Axis** → **Unit**: logs/s
- **Graph styles** → **Line width**: 2
- **Graph styles** → **Fill opacity**: 10

### Panel 3: Error count

**Typ panelu:** Stat

**Zapytanie:**

```logql
count_over_time({job="syslog"} |~ "error|fail|critical" [1h])
```

**Konfiguracja:**
- **Panel options** → **Title**: "Errors (last 1h)"
- **Standard options** → **Unit**: short
- **Stat styles** → **Color mode**: Value
- **Stat styles** → **Graph mode**: None
- **Thresholds**:
  - Green: 0-10
  - Yellow: 10-50
  - Red: 50+

### Panel 4: Log levels distribution

**Typ panelu:** Pie chart

**Zapytania (Multiple queries):**

```logql
# Query A - Info
count_over_time({job="syslog"} |~ "info|INFO" [1h])

# Query B - Warning
count_over_time({job="syslog"} |~ "warn|WARN|warning" [1h])

# Query C - Error
count_over_time({job="syslog"} |~ "error|ERROR|err" [1h])

# Query D - Critical
count_over_time({job="syslog"} |~ "critical|CRITICAL|crit" [1h])
```

**Konfiguracja:**
- **Panel options** → **Title**: "Log levels (last 1h)"
- **Legend** → **Values**: Percent
- **Pie chart** → **Pie type**: Pie

### Panel 5: Top 10 error sources

**Typ panelu:** Bar gauge

**Zapytanie:**

```logql
topk(10, sum by (hostname) (count_over_time({job="syslog"} |~ "error|fail" [1h])))
```

**Konfiguracja:**
- **Panel options** → **Title**: "Top 10 error sources"
- **Bar gauge** → **Orientation**: Horizontal
- **Bar gauge** → **Display mode**: Gradient
- **Standard options** → **Unit**: short

---

## Dashboard: Monitoring logów nginx

Przykład dashboardu do monitorowania serwera web nginx.

### Panel 1: Nginx access logs

**Typ panelu:** Logs

**Zapytanie:**

```logql
{job="nginx", type="access"}
```

**Konfiguracja:**
- **Options** → **Order**: Newest first
- **Options** → **Deduplication**: signature

### Panel 2: Requests per second

**Typ panelu:** Time series

**Zapytanie:**

```logql
sum(rate({job="nginx", type="access"}[5m]))
```

**Konfiguracja:**
- **Panel options** → **Title**: "Requests per second"
- **Axis** → **Unit**: reqps

### Panel 3: HTTP status codes

**Typ panelu:** Time series

**Zapytania (Multiple queries):**

```logql
# Query A - 2xx
sum(rate({job="nginx"} | pattern `<_> <_> <_> <_> "<_>" <status> <_>` | status >= 200 and status < 300 [5m]))

# Query B - 3xx
sum(rate({job="nginx"} | pattern `<_> <_> <_> <_> "<_>" <status> <_>` | status >= 300 and status < 400 [5m]))

# Query C - 4xx
sum(rate({job="nginx"} | pattern `<_> <_> <_> <_> "<_>" <status> <_>` | status >= 400 and status < 500 [5m]))

# Query D - 5xx
sum(rate({job="nginx"} | pattern `<_> <_> <_> <_> "<_>" <status> <_>` | status >= 500 [5m]))
```

**Konfiguracja:**
- **Panel options** → **Title**: "HTTP Status codes"
- **Legend** → **Visibility**: Visible
- **Legend** → **Placement**: Bottom
- Kolory:
  - 2xx: Zielony
  - 3xx: Niebieski
  - 4xx: Pomarańczowy
  - 5xx: Czerwony

### Panel 4: Top 10 requested URIs

**Typ panelu:** Table

**Zapytanie:**

```logql
topk(10, 
  sum by (uri) (
    count_over_time(
      {job="nginx"} 
      | pattern `<_> "<method> <uri> <_>" <_>`
      [1h]
    )
  )
)
```

**Konfiguracja:**
- **Panel options** → **Title**: "Top 10 URIs (last 1h)"
- **Table** → **Show header**: Yes
- **Column width**: Auto

### Panel 5: 4xx and 5xx errors

**Typ panelu:** Time series

**Zapytanie:**

```logql
sum(rate({job="nginx"} | pattern `<_> <_> <_> <_> "<_>" <status> <_>` | status >= 400 [5m]))
```

**Konfiguracja:**
- **Panel options** → **Title**: "HTTP errors (4xx and 5xx)"
- **Standard options** → **Color scheme**: Single color (Red)
- **Thresholds**:
  - Yellow: 1
  - Red: 10

### Panel 6: Response time percentiles

**Typ panelu:** Time series

**Zapytania (Multiple queries):**

```logql
# Query A - p50
quantile_over_time(0.5, 
  {job="nginx"} 
  | pattern `<_> <_> <time>`
  | unwrap time [5m]
)

# Query B - p90
quantile_over_time(0.9, 
  {job="nginx"} 
  | pattern `<_> <_> <time>`
  | unwrap time [5m]
)

# Query C - p99
quantile_over_time(0.99, 
  {job="nginx"} 
  | pattern `<_> <_> <time>`
  | unwrap time [5m]
)
```

**Konfiguracja:**
- **Panel options** → **Title**: "Response time percentiles"
- **Axis** → **Unit**: seconds (s)
- **Legend**: p50, p90, p99

---

## Dashboard: Monitoring aplikacji (JSON logs)

Przykład dashboardu dla aplikacji logującej w formacie JSON.

### Panel 1: Application logs

**Typ panelu:** Logs

**Zapytanie:**

```logql
{app="myapp"} | json
```

**Konfiguracja:**
- **Options** → **Prettify JSON**: Włączone
- **Options** → **Enable log details**: Włączone

### Panel 2: Errors by service

**Typ panelu:** Time series

**Zapytanie:**

```logql
sum by (service) (
  rate(
    {app="myapp"} 
    | json 
    | level="error"
    [5m]
  )
)
```

**Konfiguracja:**
- **Panel options** → **Title**: "Errors by service"
- **Legend** → **Visibility**: Visible
- **Legend** → **Values**: Last (value)

### Panel 3: Total errors

**Typ panelu:** Stat

**Zapytanie:**

```logql
sum(count_over_time({app="myapp"} | json | level="error" [24h]))
```

**Konfiguracja:**
- **Panel options** → **Title**: "Total errors (24h)"
- **Stat styles** → **Text mode**: Value and name
- **Stat styles** → **Color mode**: Background
- **Thresholds**:
  - Green: 0-100
  - Yellow: 100-500
  - Red: 500+

### Panel 4: Log levels over time

**Typ panelu:** Bar chart (stacked)

**Zapytania:**

```logql
# Query A - Debug
sum(rate({app="myapp"} | json | level="debug" [5m]))

# Query B - Info
sum(rate({app="myapp"} | json | level="info" [5m]))

# Query C - Warning
sum(rate({app="myapp"} | json | level="warning" [5m]))

# Query D - Error
sum(rate({app="myapp"} | json | level="error" [5m]))
```

**Konfiguracja:**
- **Panel options** → **Title**: "Log levels over time"
- **Bar chart** → **Stacking**: Normal
- Kolory według poziomów

### Panel 5: Top error messages

**Typ panelu:** Table

**Zapytanie:**

```logql
topk(20, 
  sum by (message) (
    count_over_time(
      {app="myapp"} 
      | json 
      | level="error"
      [1h]
    )
  )
)
```

**Konfiguracja:**
- **Panel options** → **Title**: "Top 20 error messages (last 1h)"
- **Table** → **Column width**: Auto
- **Transformations** → **Organize fields**:
  - Field: message (width: 70%)
  - Field: Value (width: 30%)

### Panel 6: Response time distribution

**Typ panelu:** Histogram

**Zapytanie:**

```logql
sum by (le) (
  rate(
    {app="myapp"} 
    | json 
    | unwrap duration
    [5m]
  )
)
```

**Konfiguracja:**
- **Panel options** → **Title**: "Response time distribution"
- **Axis** → **Unit**: milliseconds (ms)

---

## Zmienne w dashboardzie

Zmienne umożliwiają tworzenie dynamicznych dashboardów.

### Tworzenie zmiennej

1. W ustawieniach dashboardu przejdź do **Variables**
2. Kliknij **Add variable**
3. Skonfiguruj zmienną

### Przykład 1: Zmienna dla job

**Konfiguracja:**

- **Name**: `job`
- **Type**: Query
- **Data source**: Loki
- **Query**: 

```logql
label_values(job)
```

- **Multi-value**: Włączone
- **Include All option**: Włączone

**Użycie w zapytaniach:**

```logql
{job=~"$job"}
```

### Przykład 2: Zmienna dla hostname

**Konfiguracja:**

- **Name**: `hostname`
- **Type**: Query
- **Data source**: Loki
- **Query**:

```logql
label_values({job=~"$job"}, hostname)
```

- **Multi-value**: Włączone
- **Include All option**: Włączone

**Użycie w zapytaniach:**

```logql
{job=~"$job", hostname=~"$hostname"}
```

### Przykład 3: Zmienna dla poziomu logów

**Konfiguracja:**

- **Name**: `level`
- **Type**: Custom
- **Custom options**: `info,warning,error,critical`
- **Multi-value**: Włączone
- **Include All option**: Włączone

**Użycie w zapytaniach:**

```logql
{job=~"$job"} | json | level=~"$level"
```

### Przykład 4: Zmienna dla interwału czasu

**Konfiguracja:**

- **Name**: `interval`
- **Type**: Interval
- **Interval options**: `1m,5m,10m,30m,1h`
- **Auto option**: Włączone

**Użycie w zapytaniach:**

```logql
rate({job=~"$job"}[$interval])
```

---

## Adnotacje (Annotations)

Adnotacje umożliwiają wyświetlanie zdarzeń na wykresach.

### Tworzenie adnotacji z logów

1. W ustawieniach dashboardu przejdź do **Annotations**
2. Kliknij **Add annotation query**
3. Skonfiguruj adnotację

### Przykład: Deployment events

**Konfiguracja:**

- **Name**: `Deployments`
- **Data source**: Loki
- **Query**:

```logql
{job="deployment"} | json | message="deployment started"
```

- **Title field**: `version`
- **Text field**: `message`
- **Tags field**: `environment`

**Wynik:**

Na wykresach pojawią się pionowe linie w momentach deploymentów z dodatkowymi informacjami.

---

## Najlepsze praktyki dla dashboardów

### 1. Organizacja paneli

**Struktura zalecana:**

1. **Rząd 1**: Kluczowe metryki (Stats)
   - Liczba błędów
   - Liczba żądań
   - Czas odpowiedzi

2. **Rząd 2**: Wykresy czasowe (Time series)
   - Trendy w czasie
   - Porównania

3. **Rząd 3**: Szczegóły (Tables, Bar gauges)
   - Top N
   - Agregacje

4. **Rząd 4**: Surowe logi (Logs panel)
   - Ostatnie logi
   - Logi błędów

### 2. Użycie kolorów

**Konwencja kolorów:**

- **Zielony**: Wartości prawidłowe, sukces
- **Żółty**: Ostrzeżenia, wartości graniczne
- **Czerwony**: Błędy, wartości krytyczne
- **Niebieski**: Informacje, wartości neutralne

### 3. Thresholds (progi)

Ustaw progi dla automatycznego kolorowania:

**Przykład dla liczby błędów:**

- 0-10: Zielony (OK)
- 10-50: Żółty (Warning)
- 50+: Czerwony (Critical)

### 4. Nazewnictwo

**Dobre praktyki:**

- Używaj jasnych, opisowych tytułów
- Stosuj jednostki w tytułach (req/s, ms, %)
- Grupuj powiązane panele w rzędy
- Używaj spójnego nazewnictwa

**Przykłady:**

- ✅ "HTTP Errors (4xx, 5xx) - last 1h"
- ✅ "Response time p95 [ms]"
- ❌ "Panel 1"
- ❌ "Errors"

### 5. Optymalizacja wydajności

**Zasady:**

1. Ogranicz liczbę paneli (max 15-20 na dashboard)
2. Używaj odpowiednich interwałów czasowych
3. Unikaj bardzo długich zakresów czasowych (np. 7 dni)
4. Używaj zmiennych zamiast wielu dashboardów
5. Konfiguruj cache w Grafanie

### 6. Time range

**Zalecane zakresy:**

- **Real-time monitoring**: Last 5-15 minutes
- **Troubleshooting**: Last 1-6 hours
- **Analysis**: Last 24 hours - 7 days

### 7. Refresh interval

**Zalecane interwały:**

- **Production dashboards**: 30s - 1m
- **Development dashboards**: 5m - 10m
- **Historical analysis**: Off (manual refresh)

---

## Export i import dashboardów

### Export dashboardu

1. Otwórz dashboard
2. Kliknij ikonę **Share** (udostępnij)
3. Wybierz zakładkę **Export**
4. Kliknij **Save to file**
5. Plik JSON zostanie pobrany

### Import dashboardu

1. W menu bocznym wybierz **Dashboards** → **Import**
2. Kliknij **Upload JSON file** lub wklej JSON
3. Wybierz folder docelowy
4. Kliknij **Import**

### Udostępnianie dashboardu

**Metoda 1: JSON file**

```bash
# Export dashboardu przez API
curl -H "Authorization: Bearer <API_KEY>" \
  http://localhost:3000/api/dashboards/uid/<DASHBOARD_UID> > dashboard.json
```

**Metoda 2: Snapshot**

1. Kliknij ikonę **Share**
2. Wybierz zakładkę **Snapshot**
3. Ustaw **Expire**: 1 hour / 1 day / 1 week / Never
4. Kliknij **Publish to snapshots.raintank.io**
5. Skopiuj link do udostępnienia

**Uwaga:** Snapshot zawiera dane z momentu utworzenia, nie aktualizuje się.

---

## Provisioning dashboardów

Provisioning umożliwia automatyczne wdrażanie dashboardów.

### Konfiguracja provisioning

```bash
# Utworzenie katalogu provisioning
sudo mkdir -p /etc/grafana/provisioning/dashboards

# Utworzenie pliku konfiguracyjnego
sudo nano /etc/grafana/provisioning/dashboards/dashboards.yaml
```

Zawartość pliku `dashboards.yaml`:

```yaml
apiVersion: 1

providers:
  - name: 'Loki Dashboards'
    orgId: 1
    folder: 'Loki'
    type: file
    disableDeletion: false
    updateIntervalSeconds: 10
    allowUiUpdates: true
    options:
      path: /var/lib/grafana/dashboards
```

**Wyjaśnienie parametrów:**

- **name**: Nazwa providera dashboardów.
- **orgId**: ID organizacji w Grafanie. Domyślnie: 1.
- **folder**: Nazwa folderu w Grafanie gdzie umieszczone będą dashboardy.
- **type**: Typ providera. `file` oznacza pliki JSON.
- **disableDeletion**: Czy zapobiegać usuwaniu przez UI. Domyślnie: false.
- **updateIntervalSeconds**: Interwał sprawdzania zmian w plikach. Domyślnie: 10s.
- **allowUiUpdates**: Czy zezwolić na edycję przez UI. Domyślnie: true.
- **path**: Ścieżka do katalogu z plikami JSON dashboardów.

### Umieszczenie plików dashboardów

```bash
# Utworzenie katalogu dla dashboardów
sudo mkdir -p /var/lib/grafana/dashboards

# Skopiowanie pliku dashboardu
sudo cp loki-dashboard.json /var/lib/grafana/dashboards/

# Ustawienie uprawnień
sudo chown -R grafana:grafana /var/lib/grafana/dashboards

# Restart Grafany
sudo systemctl restart grafana-server
```

Dashboardy zostaną automatycznie załadowane i umieszczone w folderze "Loki".

---

## Przykładowe dashboardy gotowe do użycia

### 1. Loki Stack Monitoring

**Grafana Dashboard ID**: 14055

**Import:**

1. **Dashboards** → **Import**
2. Wpisz ID: `14055`
3. Wybierz Data Source: Loki
4. Kliknij **Import**

**Zawartość:**
- Metryki Lokiego
- Ingester statistics
- Query performance
- Storage metrics

### 2. Nginx Log Metrics

**Grafana Dashboard ID**: 13639

**Zawartość:**
- HTTP status codes
- Request rate
- Top URIs
- Error rate

### 3. System Logs

**Grafana Dashboard ID**: 12611

**Zawartość:**
- Syslog overview
- Kernel logs
- Auth logs
- Service logs

---

## Podsumowanie

Budowa dashboardów opartych o logi obejmuje:

- Wybór odpowiednich typów wizualizacji (Logs, Time series, Stat, Table)
- Tworzenie zapytań LogQL dostosowanych do typu panelu
- Konfigurację zmiennych dla dynamicznych dashboardów
- Używanie adnotacji do oznaczania zdarzeń
- Stosowanie najlepszych praktyk w organizacji paneli

**Kluczowe elementy dashboardu:**

- **Stats** - kluczowe metryki (liczba błędów, żądań)
- **Time series** - trendy i zmiany w czasie
- **Tables** - szczegółowe dane agregowane
- **Logs panel** - surowe logi do debugowania

**Typy dashboardów:**

- **System logs** - monitoring logów systemowych
- **Application logs** - monitoring aplikacji
- **Web server logs** - monitoring nginx/apache
- **Custom logs** - aplikacje z logami JSON

**Następne kroki:**

- Warsztat praktyczny - monitorowanie logów systemowych
- Konfiguracja alertów na podstawie dashboardów
- Optymalizacja zapytań LogQL
