# Integracja z Grafaną

Integracja Lokiego z Grafaną umożliwia wizualizację logów, tworzenie zapytań LogQL oraz korelację logów z metrykami z Prometheusa. Grafana zapewnia pełne wsparcie dla Lokiego jako źródła danych (Data Source).

## Wymagania wstępne

Przed rozpoczęciem integracji należy upewnić się, że:

- **Loki** jest zainstalowany i uruchomiony (domyślnie na porcie 3100)
- **Grafana** jest zainstalowana i uruchomiona (domyślnie na porcie 3000)
  - Proces instalacji Grafany opisany jest w: [Moduł 1 - Instalacja i konfiguracja Grafana OSS](../Moduł%201%20-%20Podstawy%20Grafany%20i%20architektura/2.%20Instalacja%20i%20konfiguracja%20Grafana%20OSS.md)
- Dostęp sieciowy między Grafaną a Lokim jest możliwy
- Znane są dane dostępowe do Grafany (domyślnie: admin/admin)

---

## Dodawanie Lokiego jako Data Source

### Metoda 1: Przez interfejs webowy

#### Krok 1: Przejście do konfiguracji Data Sources

1. Zaloguj się do Grafany
2. W menu bocznym wybierz **Connections** → **Data sources**
3. Kliknij przycisk **Add data source**
4. W sekcji **Logging & document databases** wybierz **Loki**

#### Krok 2: Konfiguracja połączenia

Wypełnij formularz konfiguracji:

**Podstawowe ustawienia:**

- **Name**: `Loki` (lub inna nazwa identyfikująca źródło)
- **URL**: `http://localhost:3100` (adres serwera Lokiego)
- **Access**: `Server (default)` - Grafana łączy się z Lokim z serwera backend

**Opcjonalne ustawienia:**

- **Timeout**: `60` (timeout zapytań w sekundach)
- **HTTP Method**: `GET` lub `POST` (domyślnie GET)

#### Krok 3: Konfiguracja zaawansowana (opcjonalnie)

**Derived fields** - mapowanie pól z logów do linków:

```
Name: traceID
Regex: traceID=(\w+)
URL: http://tempo:3200/trace/${__value.raw}
```

**Umożliwia to:**
- Przejście z logu do trace w systemie distributed tracing (np. Tempo)
- Korelację logów z innymi źródłami danych

#### Krok 4: Zapisanie i testowanie

1. Kliknij **Save & test** na dole strony
2. Grafana wykona testowe zapytanie do Lokiego
3. Komunikat sukcesu: **Data source is working**

W przypadku błędu sprawdź:
- Czy Loki jest uruchomiony: `sudo systemctl status loki`
- Czy port 3100 jest dostępny: `curl http://localhost:3100/ready`
- Czy adres URL jest poprawny
- Czy firewall nie blokuje połączenia

### Metoda 2: Provisioning (automatyczna konfiguracja)

Provisioning umożliwia automatyczną konfigurację Data Sources przy starcie Grafany.

#### Utworzenie pliku provisioning

```bash
# Utworzenie katalogu provisioning (jeśli nie istnieje)
sudo mkdir -p /etc/grafana/provisioning/datasources

# Utworzenie pliku konfiguracyjnego dla Lokiego
sudo nano /etc/grafana/provisioning/datasources/loki.yaml
```

Zawartość pliku `loki.yaml`:

```yaml
apiVersion: 1

datasources:
  - name: Loki
    type: loki
    access: proxy
    url: http://localhost:3100
    jsonData:
      maxLines: 1000
      derivedFields:
        - datasourceUid: tempo
          matcherRegex: "traceID=(\\w+)"
          name: TraceID
          url: '$${__value.raw}'
    editable: true
    version: 1
```

**Wyjaśnienie parametrów:**

- **name**: Nazwa Data Source w Grafanie.
- **type**: Typ źródła danych. Dla Lokiego: `loki`.
- **access**: Tryb dostępu. `proxy` oznacza połączenie przez backend Grafany.
- **url**: URL do serwera Lokiego.
- **maxLines**: Maksymalna liczba linii zwracanych w zapytaniu. Domyślnie: 1000.
- **derivedFields**: Konfiguracja pól pochodnych do korelacji danych.
- **editable**: Czy Data Source można edytować przez interfejs webowy.

#### Restart Grafany

```bash
# Restart usługi Grafany
sudo systemctl restart grafana-server

# Sprawdzenie logów
sudo journalctl -u grafana-server -f
```

Po restarcie Data Source "Loki" będzie automatycznie dostępny w Grafanie.

### Metoda 3: Przez API Grafany

Dodanie Data Source za pomocą REST API:

```bash
# Dodanie Lokiego przez API Grafany
curl -X POST http://admin:admin@localhost:3000/api/datasources \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Loki",
    "type": "loki",
    "url": "http://localhost:3100",
    "access": "proxy",
    "basicAuth": false,
    "isDefault": false,
    "jsonData": {
      "maxLines": 1000
    }
  }'
```

**Uwaga:** Zmień `admin:admin` na właściwe dane logowania.

---

## Explore - eksploracja logów

**Explore** to interaktywne narzędzie w Grafanie do eksploracji danych bez konieczności tworzenia dashboardów.

### Uruchomienie Explore

1. W menu bocznym Grafany wybierz ikonę **Explore** (kompas)
2. W górnym menu wybierz Data Source: **Loki**
3. W polu zapytania wpisz zapytanie LogQL

### Interfejs Explore

Interfejs składa się z kilku sekcji:

**1. Query editor** - edytor zapytań LogQL

```logql
{job="varlogs"}
```

**2. Time range picker** - wybór zakresu czasowego
- Last 5 minutes
- Last 15 minutes
- Last 1 hour
- Custom range

**3. Log browser** - przeglądarka etykiet
- Wybór etykiet z listy
- Automatyczne podpowiedzi
- Filtrowanie wartości

**4. Results** - wyniki zapytania
- Wyświetlanie logów w formie tekstowej
- Kolorowanie składni
- Rozwijanie/zwijanie wpisów

**5. Statistics** - statystyki zapytania
- Liczba zwróconych linii
- Zakres czasowy
- Liczba unikalnych strumieni

### Podstawowe zapytania w Explore

#### Przykład 1: Wszystkie logi z określonego job

```logql
{job="nginx"}
```

#### Przykład 2: Filtrowanie po zawartości

```logql
{job="nginx"} |= "error"
```

#### Przykład 3: Wykluczenie wzorca

```logql
{job="nginx"} != "debug"
```

#### Przykład 4: Wyrażenia regularne

```logql
{job="nginx"} |~ "error|warning|critical"
```

#### Przykład 5: Parsowanie JSON

```logql
{job="api"} | json | status_code >= 400
```

### Funkcje Explore

#### 1. Live tail

Przeglądanie logów w czasie rzeczywistym:

1. Kliknij przycisk **Live** w prawym górnym rogu
2. Logi będą aktualizowane automatycznie
3. Przydatne do debugowania na żywo

#### 2. Log context

Wyświetlanie kontekstu wokół wybranego logu:

1. Kliknij na wybrany wpis logu
2. Wybierz **Show context**
3. Grafana wyświetli logi przed i po wybranym wpisie

#### 3. Kopiowanie zapytań

Skopiowanie zapytania do schowka:

1. Kliknij ikonę **Copy** obok pola zapytania
2. Zapytanie można wkleić w innym miejscu

#### 4. Dodawanie do dashboardu

Dodanie zapytania bezpośrednio do dashboardu:

1. Kliknij **Add** → **Add to dashboard**
2. Wybierz istniejący dashboard lub utwórz nowy
3. Zapytanie zostanie dodane jako panel

---

## LogQL - język zapytań Lokiego

LogQL to język zapytań używany do przeszukiwania i analizy logów w Lokiego. Składnia inspirowana PromQL.

### Struktura zapytania LogQL

Zapytanie LogQL składa się z:

1. **Log stream selector** - wybór strumieni na podstawie etykiet
2. **Log pipeline** - operacje na zawartości logów

```logql
{<selektory etykiet>} <pipeline>
```

### Log stream selector

Wybór strumieni logów na podstawie etykiet:

#### Operatory dopasowania etykiet:

- `=` - równość (exact match)
- `!=` - nierówność
- `=~` - dopasowanie regex
- `!~` - niedopasowanie regex

#### Przykłady:

```logql
# Dokładne dopasowanie
{job="nginx"}

# Wiele etykiet (AND)
{job="nginx", environment="production"}

# Nierówność
{job!="test"}

# Regex
{job=~"nginx|apache"}

# Niedopasowanie regex
{environment!~"dev|test"}
```

### Log pipeline - filtrowanie zawartości

#### Line filter operators:

- `|=` - zawiera tekst (contains)
- `!=` - nie zawiera tekstu
- `|~` - dopasowanie regex
- `!~` - niedopasowanie regex

#### Przykłady:

```logql
# Logi zawierające słowo "error"
{job="nginx"} |= "error"

# Logi NIE zawierające "debug"
{job="nginx"} != "debug"

# Regex - error lub warning
{job="nginx"} |~ "error|warning"

# Łańcuch filtrów
{job="nginx"} |= "error" != "timeout"
```

### Parser operators - parsowanie logów

#### JSON parser:

```logql
# Parsowanie logów JSON
{job="api"} | json

# Dostęp do pól JSON
{job="api"} | json | status_code >= 400

# Filtrowanie po zagnieżdżonych polach
{job="api"} | json | response_body_size > 1000000
```

#### Logfmt parser:

```logql
# Parsowanie formatu logfmt
{job="app"} | logfmt

# Filtrowanie po sparsowanych polach
{job="app"} | logfmt | level="error"
```

#### Pattern parser:

```logql
# Parsowanie z użyciem wzorca
{job="nginx"} | pattern `<ip> - - <_> "<method> <uri> <_>" <status> <_>`

# Filtrowanie po sparsowanych polach
{job="nginx"} | pattern `<ip> - - <_> "<method> <uri> <_>" <status> <_>` | status >= 400
```

#### Regex parser:

```logql
# Parsowanie z użyciem regex
{job="nginx"} | regexp `^(?P<ip>\\S+) .* \"(?P<method>\\S+) (?P<uri>\\S+) .*\" (?P<status>\\d+)`

# Filtrowanie
{job="nginx"} | regexp `^(?P<ip>\\S+)` | ip = "192.168.1.1"
```

### Formatowanie output:

#### Line format:

```logql
# Formatowanie wyświetlanego logu
{job="nginx"} | json | line_format "{{.method}} {{.uri}} - {{.status}}"
```

#### Label format:

```logql
# Dodanie lub modyfikacja etykiet
{job="api"} | json | label_format level="{{.severity}}"
```

### Metric queries - agregacje

LogQL umożliwia tworzenie metryk z logów:

#### Rate - szybkość logów:

```logql
# Liczba logów na sekundę
rate({job="nginx"}[5m])

# Szybkość błędów
rate({job="nginx"} |= "error" [5m])
```

#### Count_over_time - liczba logów:

```logql
# Suma logów w czasie
count_over_time({job="nginx"}[5m])

# Liczba błędów w ostatniej godzinie
count_over_time({job="nginx"} |= "error" [1h])
```

#### Bytes_over_time - suma bajtów:

```logql
# Suma bajtów w czasie
bytes_over_time({job="nginx"}[5m])
```

#### Agregacje:

```logql
# Suma wszystkich błędów z różnych hostów
sum(rate({job="nginx"} |= "error" [5m]))

# Grupowanie po etykietach
sum by (host) (rate({job="nginx"}[5m]))

# Top 10 hostów z największą liczbą logów
topk(10, sum by (host) (rate({job="nginx"}[5m])))
```

### Przykłady zaawansowanych zapytań

#### Przykład 1: Analiza kodów HTTP

```logql
# Parsowanie logów nginx i zliczanie kodów 4xx i 5xx
sum by (status) (
  count_over_time(
    {job="nginx"} 
    | pattern `<_> <_> <_> <_> "<_>" <status> <_>`
    | status >= 400
    [5m]
  )
)
```

#### Przykład 2: Top 10 najczęstszych błędów

```logql
topk(10, 
  sum by (error_message) (
    count_over_time(
      {job="application"} 
      | json 
      | level="error"
      [24h]
    )
  )
)
```

#### Przykład 3: Wykrywanie anomalii w czasie odpowiedzi

```logql
# Średni czas odpowiedzi
avg_over_time(
  {job="api"} 
  | json 
  | unwrap response_time
  [5m]
)
```

#### Przykład 4: Analiza logów z wielu źródeł

```logql
# Błędy ze wszystkich aplikacji w środowisku produkcyjnym
sum by (app) (
  rate(
    {environment="production"} |= "error"
    [5m]
  )
)
```

---

## Konfiguracja alertów na podstawie logów

Grafana umożliwia tworzenie alertów na podstawie zapytań LogQL.

### Tworzenie alertu

#### Krok 1: Utworzenie panelu z metryką

1. Utwórz nowy dashboard lub edytuj istniejący
2. Dodaj panel typu **Time series**
3. Wybierz Data Source: **Loki**
4. Wpisz zapytanie metryczne (metric query):

```logql
sum(rate({job="nginx"} |= "error" [5m]))
```

#### Krok 2: Konfiguracja reguły alertu

1. W ustawieniach panelu przejdź do zakładki **Alert**
2. Kliknij **Create alert rule from this panel**
3. Skonfiguruj warunki alertu:

**Warunki przykładowe:**

```
WHEN last() OF query(A, 5m, now) IS ABOVE 10
```

**Znaczenie:**
- Ostatnia wartość z zapytania A
- Z ostatnich 5 minut
- Jest większa niż 10

#### Krok 3: Konfiguracja powiadomień

1. Wybierz **Contact point** (kanał powiadomień)
2. Ustaw **Evaluation interval** (np. co 1 minutę)
3. Dodaj etykiety i adnotacje
4. Zapisz regułę alertu

### Przykładowe reguły alertów

#### Alert 1: Wysoka liczba błędów

```logql
# Zapytanie
sum(rate({job="nginx"} |= "error" [5m])) > 10
```

**Warunek:** Alert gdy liczba błędów przekracza 10/s

#### Alert 2: Błędy aplikacji krytycznej

```logql
# Zapytanie
count_over_time({app="payment", level="critical"}[5m]) > 0
```

**Warunek:** Alert gdy wystąpi jakikolwiek błąd krytyczny

#### Alert 3: Brak logów (heartbeat)

```logql
# Zapytanie
count_over_time({job="api"}[5m]) < 10
```

**Warunek:** Alert gdy liczba logów spadnie poniżej 10 w 5 minut

---

## Korelacja logów z metrykami

Grafana umożliwia korelację logów z Lokiego z metrykami z Prometheusa.

### Przykład: Dashboard z metrykami i logami

#### Panel 1: Metryki CPU (Prometheus)

```promql
rate(node_cpu_seconds_total{mode!="idle"}[5m])
```

#### Panel 2: Logi systemowe (Loki)

```logql
{job="syslog"}
```

#### Panel 3: Błędy aplikacji (Loki metryka)

```logql
sum(rate({job="app"} |= "error" [5m]))
```

### Data links - linkowanie między panelami

Konfiguracja linków między danymi:

1. W ustawieniach panelu z metrykami przejdź do **Data links**
2. Dodaj link:

```
Title: View logs
URL: /explore?left={"datasource":"Loki","queries":[{"expr":"{job=\"${job}\"}"}]}
```

Po kliknięciu w metrykę nastąpi przekierowanie do Explore z odpowiednim zapytaniem do logów.

---

## Optymalizacja zapytań

### Dobre praktyki

1. **Używaj selektorów etykiet do wstępnego filtrowania**

```logql
# ✅ DOBRE - najpierw selektor etykiet
{job="nginx", host="server01"} |= "error"

# ❌ ZŁE - zbyt szeroki selektor
{job="nginx"} |= "error" |= "server01"
```

2. **Ogranicz zakres czasowy**

```logql
# ✅ DOBRE - konkretny zakres
count_over_time({job="nginx"}[5m])

# ❌ ZŁE - zbyt długi zakres
count_over_time({job="nginx"}[24h])
```

3. **Używaj metryk queries zamiast log queries dla wizualizacji**

```logql
# ✅ DOBRE - metryka dla wykresu
rate({job="nginx"} |= "error" [5m])

# ❌ ZŁE - logi dla wykresu
{job="nginx"} |= "error"
```

4. **Ogranicz kardynalność etykiet**

```logql
# ✅ DOBRE - niskokardinalne etykiety
{job="api", environment="prod"}

# ❌ ZŁE - wysokokardinalne (user_id ma tysiące wartości)
{job="api", user_id="12345"}
```

### Limity i ograniczenia

Domyślne limity w Lokiego:

- **Max entries limit**: 5000 linii na zapytanie
- **Max query length**: 5m dla metric queries
- **Max query time**: 30s timeout

Można je dostosować w konfiguracji Data Source w Grafanie:

```yaml
jsonData:
  maxLines: 10000
  timeout: 60
```

---

## Troubleshooting integracji

### Problem 1: "Data source is not working"

**Diagnostyka:**

```bash
# Sprawdzenie czy Loki odpowiada
curl http://localhost:3100/ready

# Sprawdzenie logów Lokiego
sudo journalctl -u loki -n 50

# Sprawdzenie logów Grafany
sudo journalctl -u grafana-server -n 50
```

**Rozwiązania:**
- Sprawdź czy URL do Lokiego jest poprawny
- Sprawdź czy Loki jest uruchomiony
- Sprawdź firewall i reguły sieciowe
- Sprawdź logi Grafany pod kątem błędów połączenia

### Problem 2: "No logs found"

**Przyczyny:**
- Brak logów w wybranym zakresie czasowym
- Niepoprawne zapytanie LogQL
- Brak danych w Lokiego

**Diagnostyka:**

```bash
# Sprawdzenie czy Loki ma jakieś dane
curl -s "http://localhost:3100/loki/api/v1/labels" | jq

# Lista wartości dla etykiety job
curl -s "http://localhost:3100/loki/api/v1/label/job/values" | jq
```

### Problem 3: Powolne zapytania

**Optymalizacja:**

1. Ogranicz zakres czasowy
2. Użyj bardziej specyficznych selektorów etykiet
3. Zwiększ zasoby Lokiego (RAM, CPU)
4. Skonfiguruj cache w Lokiego
5. Używaj metric queries zamiast log queries dla agregacji

### Problem 4: Timeout zapytań

**Rozwiązanie:**

Zwiększ timeout w konfiguracji Data Source:

1. Przejdź do **Configuration** → **Data sources** → **Loki**
2. W sekcji **HTTP** zwiększ **Timeout** (np. do 120s)
3. Zapisz zmiany

---

## Podsumowanie

Integracja Lokiego z Grafaną obejmuje:

- Dodanie Lokiego jako Data Source (webUI, provisioning, API)
- Używanie Explore do interaktywnej eksploracji logów
- Tworzenie zapytań LogQL do przeszukiwania i analizy logów
- Konfigurację alertów na podstawie wzorców w logach
- Korelację logów z metrykami z innych źródeł

**Kluczowe funkcje:**

- **Explore**: Interaktywna eksploracja logów
- **LogQL**: Język zapytań do przeszukiwania logów
- **Live tail**: Przeglądanie logów w czasie rzeczywistym
- **Alerting**: Powiadomienia na podstawie logów
- **Data links**: Korelacja między różnymi źródłami danych

**Następne kroki:**

- Budowa dashboardów opartych o logi
- Tworzenie zaawansowanych zapytań LogQL
- Konfiguracja alertów
- Instalacja i konfiguracja Promtail (agent do zbierania logów)
