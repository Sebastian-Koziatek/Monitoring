# Elasticsearch

## Wprowadzenie

Elasticsearch to rozproszony silnik wyszukiwania i analityki danych, który w połączeniu z Grafaną umożliwia zaawansowaną analizę logów i metryk aplikacyjnych. W tym rozdziale poznasz podstawy Elasticsearch, proces instalacji, kluczowe funkcje oraz integrację z platformą Grafana.

## Czym jest Elasticsearch

Elasticsearch to rozproszony silnik wyszukiwania i analityki, zbudowany na bibliotece Apache Lucene. Jest częścią stosu Elastic Stack (dawniej ELK Stack: Elasticsearch, Logstash, Kibana), zaprojektowanego do przechowywania, indeksowania, wyszukiwania i analizowania dużych wolumenów danych w czasie rzeczywistym.

### Kluczowe cechy

- **Architektura rozproszona**: Clustering, sharding i replikacja zapewniają skalowalność poziomą i wysoką dostępność.
- **Near real-time search**: Dane są indeksowane i dostępne do przeszukiwania w czasie zbliżonym do rzeczywistego (odświeżanie indeksów co ~1 sekundę).
- **RESTful API**: Wszystkie operacje (CRUD, wyszukiwanie, administracja) wykonywane są przez HTTP/JSON.
- **Query DSL**: Zaawansowany język zapytań oparty na JSON, umożliwiający złożone wyszukiwania, filtrowanie i agregacje.
- **Schema-free (dynamic mapping)**: Automatyczne wykrywanie typów pól z możliwością definiowania własnych mappings.
- **Aggregations**: Potężny framework do budowania analiz, statystyk, histogramów i grupowania danych.

### Model danych

Elasticsearch wykorzystuje model dokumentowy, gdzie dane przechowywane są w formacie JSON. Każdy dokument jest indeksowany i może być szybko wyszukany według różnych kryteriów.

**Podstawowe koncepcje:**
- **Index**: Logiczny kontener dla dokumentów (analogia do bazy danych).
- **Document**: Pojedyncza jednostka danych w formacie JSON.
- **Field**: Pole w dokumencie (analogia do kolumny w bazie danych).
- **Shard**: Fragment indeksu umożliwiający rozproszenie danych.
- **Replica**: Kopia shardu zapewniająca wysoką dostępność.

### Zastosowania

Elasticsearch stosowany jest w wielu scenariuszach:
- Wyszukiwarki aplikacyjne (full-text search).
- Analiza logów i SIEM (Security Information and Event Management).
- Monitoring wydajności aplikacji (APM - Application Performance Monitoring).
- Business intelligence i analiza metryk biznesowych.
- Analiza zachowań użytkowników.

### Rola w połączeniu z Grafaną

W architekturze opartej o Grafanę, Elasticsearch pełni najczęściej funkcję repozytorium logów i zdarzeń aplikacyjnych. Typowy scenariusz to ELK/EFK Stack, gdzie logi są zbierane przez Logstash/Fluentd/Filebeat, indeksowane w Elasticsearch i wizualizowane w Kibanie lub Grafanie.

**Typowy przepływ danych:**

```
Aplikacje/Serwery → Filebeat/Logstash → Elasticsearch → Grafana
                                              ↓
                                           Kibana
```

**Różnica względem Loki:**

| Właściwość | Elasticsearch | Loki |
|-----------|---------------|------|
| **Indeksowanie** | Pełne indeksowanie treści logów | Tylko labels (metadata) |
| **Wyszukiwanie** | Full-text search, regex, fuzzy | Grep-like queries |
| **Zasoby** | Większe wymagania | Niższe koszty storage |
| **Optymalizacja** | Złożone agregacje i analityka | Stream-based log queries |

## Instalacja Elasticsearch

W tej sekcji omówimy proces instalacji Elasticsearch na systemie Ubuntu/Debian. Instalację przeprowadzimy przy użyciu pakietów APT dostarczanych przez Elastic.

### Wymagania wstępne

Przed rozpoczęciem instalacji upewnij się, że:
- System operacyjny: Ubuntu 20.04/22.04/24.04 LTS lub Debian 11/12.
- Minimum 4 GB RAM (zalecane 8–16 GB dla środowiska produkcyjnego).
- Java nie jest wymagana – Elasticsearch 7.x+ zawiera wbudowane środowisko JVM.
- Uprawnienia root lub sudo.

### Instalacja z repozytorium APT

#### Krok 1: Import klucza GPG

Pobierz i dodaj klucz GPG repozytorium Elastic:

```bash
# Pobranie i dodanie klucza GPG
wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
```

**Wyjaśnienie:**
- `wget -qO -`: Pobiera klucz w trybie cichym i wypisuje na standardowe wyjście.
- `gpg --dearmor`: Konwertuje klucz do formatu binarnego.
- `-o /usr/share/keyrings/`: Zapisuje klucz w standardowej lokalizacji dla kluczy APT.

#### Krok 2: Dodanie repozytorium

Dodaj repozytorium Elastic do źródeł APT:

```bash
# Dodanie repozytorium Elasticsearch do sources.list.d
echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-8.x.list
```

**Wyjaśnienie:**
- `deb [signed-by=...]`: Określa repozytorium APT z kluczem podpisującym.
- `8.x`: Określa wersję główną Elasticsearch (użyj `7.x` dla starszej wersji).
- `stable main`: Kanał stabilny z głównymi pakietami.

#### Krok 3: Aktualizacja listy pakietów i instalacja

```bash
# Aktualizacja indeksu pakietów
sudo apt update

# Instalacja Elasticsearch
sudo apt install elasticsearch -y
```

**WAŻNE**: Podczas pierwszej instalacji Elasticsearch 8.x automatycznie generuje hasło dla użytkownika `elastic` i certyfikaty TLS. Zapisz wyświetlone hasło w bezpiecznym miejscu.

#### Krok 4: Konfiguracja podstawowa

Edytuj plik konfiguracyjny Elasticsearch:

```bash
# Edycja pliku konfiguracyjnego
sudo nano /etc/elasticsearch/elasticsearch.yml
```

Przykładowa konfiguracja dla single-node cluster:

```yaml
# Nazwa klastra
cluster.name: monitoring-cluster

# Nazwa węzła
node.name: node-1

# Ścieżka do danych
path.data: /var/lib/elasticsearch

# Ścieżka do logów
path.logs: /var/log/elasticsearch

# Adres sieciowy (localhost dla testów, 0.0.0.0 dla dostępu zdalnego)
network.host: localhost

# Port HTTP
http.port: 9200

# Discovery dla single-node (wyłącza wymaganie cluster bootstrap)
discovery.type: single-node

# Bezpieczeństwo (Elasticsearch 8.x domyślnie włącza security)
xpack.security.enabled: true
xpack.security.enrollment.enabled: true
```

**Wyjaśnienie kluczowych parametrów:**
- **cluster.name**: Identyfikator klastra. Węzły o tej samej nazwie łączą się automatycznie.
- **node.name**: Unikalna nazwa węzła w klastrze.
- **network.host**: localhost (127.0.0.1) dla lokalnego dostępu, 0.0.0.0 dla dostępu z zewnątrz.
- **discovery.type: single-node**: Tryb pojedynczego węzła – wyłącza wymóg bootstrap klastra (tylko dla testów/dev).
- **xpack.security.enabled**: Włącza uwierzytelnianie i TLS (domyślnie true w wersji 8.x).

**Uwaga:** Dla środowiska produkcyjnego zawsze używaj klastra złożonego z minimum 3 węzłów (master-eligible nodes) dla zapewnienia wysokiej dostępności.

#### Krok 5: Uruchomienie i włączenie Elasticsearch

```bash
# Uruchomienie usługi Elasticsearch
sudo systemctl start elasticsearch

# Włączenie autostartu przy boocie systemu
sudo systemctl enable elasticsearch

# Sprawdzenie statusu usługi
sudo systemctl status elasticsearch
```

#### Krok 6: Weryfikacja instalacji

Sprawdź czy Elasticsearch działa poprawnie:

```bash
# Test połączenia do Elasticsearch (bez uwierzytelniania - wersja 7.x)
curl -X GET "localhost:9200/"

# Test z uwierzytelnianiem (wersja 8.x)
curl -X GET "https://localhost:9200/" -u elastic:<HASŁO> --cacert /etc/elasticsearch/certs/http_ca.crt
```

Przykładowa odpowiedź:

```json
{
  "name" : "node-1",
  "cluster_name" : "monitoring-cluster",
  "cluster_uuid" : "abc123xyz",
  "version" : {
    "number" : "8.11.0",
    "build_flavor" : "default",
    "build_type" : "deb",
    "build_hash" : "...",
    "build_date" : "...",
    "lucene_version" : "9.8.0"
  },
  "tagline" : "You Know, for Search"
}
```

**Wyjaśnienie:**
- **name**: Nazwa węzła z pliku konfiguracyjnego.
- **cluster_name**: Nazwa klastra.
- **version.number**: Zainstalowana wersja Elasticsearch.
- **tagline**: Charakterystyczny slogan Elasticsearch.

### Konfiguracja hasła użytkownika (Elasticsearch 8.x)

Jeśli nie zapisano hasła podczas instalacji lub potrzebujesz je zresetować:

```bash
# Reset hasła dla użytkownika elastic
sudo /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic
```

### Wyłączenie bezpieczeństwa (tylko dla środowiska testowego)

Jeśli chcesz uprościć konfigurację dla celów szkoleniowych:

```yaml
# W pliku /etc/elasticsearch/elasticsearch.yml
xpack.security.enabled: false
```

Po zmianie, zrestartuj usługę:

```bash
sudo systemctl restart elasticsearch
```

**Uwaga:** Nigdy nie wyłączaj security w środowisku produkcyjnym. Zawsze używaj TLS i uwierzytelniania.

## Podstawowe funkcje Elasticsearch

Po zainstalowaniu poznaj kluczowe funkcje Elasticsearch dostępne przez REST API.

### Sprawdzenie zdrowia klastra

```bash
# Sprawdzenie stanu klastra
curl -X GET "localhost:9200/_cluster/health?pretty"
```

Przykładowa odpowiedź:

```json
{
  "cluster_name" : "monitoring-cluster",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 1,
  "number_of_data_nodes" : 1,
  "active_primary_shards" : 5,
  "active_shards" : 5,
  "unassigned_shards" : 0
}
```

**Wyjaśnienie statusów:**
- **green**: Wszystkie shardy są przydzielone (primary + replica).
- **yellow**: Wszystkie primary shards są przydzielone, ale brakuje niektórych replik.
- **red**: Niektóre primary shards nie są przydzielone – brak danych.

### Tworzenie indeksu

Utwórz pierwszy indeks testowy:

```bash
# Utworzenie indeksu o nazwie "aplikacja-logs"
curl -X PUT "localhost:9200/aplikacja-logs?pretty"
```

Odpowiedź:

```json
{
  "acknowledged" : true,
  "shards_acknowledged" : true,
  "index" : "aplikacja-logs"
}
```

### Dodawanie dokumentu

Dodaj dokument JSON do indeksu:

```bash
# Dodanie dokumentu z automatycznym ID
curl -X POST "localhost:9200/aplikacja-logs/_doc?pretty" -H 'Content-Type: application/json' -d'
{
  "@timestamp": "2026-02-09T10:30:00Z",
  "level": "ERROR",
  "service": "api",
  "message": "Connection timeout to database",
  "user_id": "12345"
}
'
```

**Wyjaśnienie:**
- `_doc`: Standardowy typ dokumentu w Elasticsearch 7.x+.
- `@timestamp`: Pole czasowe (konwencja dla time-series data).
- Automatyczne ID zostanie wygenerowane przez Elasticsearch.

### Wyszukiwanie dokumentów

Wyszukaj dokumenty w indeksie:

```bash
# Wyszukanie wszystkich dokumentów
curl -X GET "localhost:9200/aplikacja-logs/_search?pretty"

# Wyszukanie dokumentów z poziomem ERROR
curl -X GET "localhost:9200/aplikacja-logs/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "match": {
      "level": "ERROR"
    }
  }
}
'
```

### Agregacje

Wykonaj agregację – zlicz dokumenty według poziomu logu:

```bash
# Agregacja według pola "level"
curl -X GET "localhost:9200/aplikacja-logs/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "size": 0,
  "aggs": {
    "levels": {
      "terms": {
        "field": "level.keyword"
      }
    }
  }
}
'
```

**Wyjaśnienie:**
- `size: 0`: Nie zwracaj dokumentów, tylko wyniki agregacji.
- `terms`: Agregacja bucketing – grupuje dokumenty według unikalnych wartości pola.
- `level.keyword`: Pole typu keyword (nie analizowane) używane do agregacji.

### Usuwanie indeksu

```bash
# Usunięcie indeksu
curl -X DELETE "localhost:9200/aplikacja-logs?pretty"
```

## Połączenie Elasticsearch z Grafaną

Po zainstalowaniu Elasticsearch skonfiguruj go jako źródło danych w Grafanie.

### Dodanie datasource w Grafanie

1. **Dodanie źródła danych:**
   - W Grafanie: Configuration → Data Sources → Add data source → Elasticsearch

2. **Parametry połączenia:**
   - **URL**: Adres klastra Elasticsearch (np. `http://elasticsearch:9200`)
   - **Index name**: Wzorzec indeksu z wildcard (np. `logstash-*`, `filebeat-*`, `[logstash-]YYYY.MM.DD`)
   - **Time field**: Pole timestamp używane do filtrowania czasowego (domyślnie `@timestamp`)
   - **Version**: Wersja Elasticsearch (7.x+, 8.x) – wpływa na składnię zapytań
   - **Authentication**: Basic Auth, API Key lub bez uwierzytelnienia (niezalecane produkcyjnie)
   - **TLS/SSL**: Konfiguracja certyfikatów dla HTTPS

3. **Zaawansowane opcje:**
   - **Min time interval**: Minimalna rozdzielczość agregacji czasowej
   - **Max concurrent Shard Requests**: Limit równoległych zapytań (optymalizacja wydajności)
   - **Log level field**: Pole określające poziom logu (INFO, WARN, ERROR) dla kolorowania

4. **Testowanie połączenia:**
   - "Save & Test" weryfikuje dostęp do klastra i poprawność indeksów

#### Przykładowe zapytanie Lucene (Query String)

```lucene
level:ERROR AND service:api AND message:*timeout*
```

#### Przykładowe zapytanie JSON (Elasticsearch Query DSL) w metrykach

```json
{
  "query": {
    "bool": {
      "must": [
        {"match": {"service": "api"}},
        {"range": {"@timestamp": {"gte": "now-1h"}}}
      ]
    }
  },
  "aggs": {
    "errors_over_time": {
      "date_histogram": {
        "field": "@timestamp",
        "interval": "1m"
      },
      "aggs": {
        "error_count": {
          "filter": {"term": {"level": "ERROR"}}
        }
      }
    }
  }
}
```

#### Provisioning jako kod (YAML)

```yaml
apiVersion: 1
datasources:
  - name: Elasticsearch
    type: elasticsearch
    access: proxy
    url: http://elasticsearch:9200
    database: "[logstash-]YYYY.MM.DD"
    jsonData:
      timeField: "@timestamp"
      esVersion: "8.0.0"
      logLevelField: "level"
      logMessageField: "message"
      maxConcurrentShardRequests: 5
    secureJsonData:
      basicAuthPassword: ${ELASTIC_PASSWORD}
```

### Do jakich zastosowań warto używać Elasticsearch z Grafaną

#### 1. **Centralizacja i analiza logów aplikacyjnych**
- Agregacja logów z wielu źródeł (aplikacje, serwery, kontenery)
- Full-text search w logach (wyszukiwanie stack traces, error messages, transaction IDs)
- Analiza trendów błędów i anomalii

**Korzyści:**
- Elasticsearch świetnie radzi sobie z wyszukiwaniem pełnotekstowym w dużych wolumenach
- Możliwość definiowania złożonych zapytań (wildcards, regex, fuzzy search)
- Grafana umożliwia tworzenie dashboardów korelujących logi z metrykami

#### 2. **Application Performance Monitoring (APM)**
- Integracja z Elastic APM: traces, spans, transaction metrics
- Analiza latencji, throughput, error rate
- Distributed tracing w architekturach mikroserwisowych

**Korzyści:**
- Elastic APM automatycznie instrumentuje aplikacje (Java, .NET, Node.js, Python, Ruby, Go)
- Grafana jako unified observability platform (metryki + logi + traces)
- Możliwość korelacji APM data z infrastrukturą (Prometheus) w jednym widoku

#### 3. **Security Information and Event Management (SIEM)**
- Analiza logów bezpieczeństwa (firewall, IDS/IPS, auth logs)
- Detekcja anomalii i potencjalnych zagrożeń
- Audyt dostępu i compliance reporting

**Korzyści:**
- Elastic SIEM oferuje gotowe detection rules i dashboardy
- Grafana może służyć jako NOC/SOC dashboard dla team security
- Integracja z alertingiem (Grafana Alert Rules) dla krytycznych zdarzeń

#### 4. **Business Intelligence i metryki biznesowe**
- Analiza transakcji e-commerce, konwersji, user journeys
- Agregacja danych z application logs (purchase, signup, checkout)
- Time-series analysis of business KPIs

**Korzyści:**
- Elasticsearch aggregations (terms, stats, percentiles, date_histogram) idealne do BI
- Grafana umożliwia tworzenie executive dashboards z KPIs biznesowymi
- Możliwość korelacji metryk biznesowych z technical metrics (np. spadek konwersji vs. wzrost error rate)

#### 5. **Monitoring infrastruktury (Metricbeat, system logs)**
- Zbieranie metryk systemowych (CPU, RAM, disk, network) przez Metricbeat → Elasticsearch
- Monitoring infrastruktury sieciowej (SNMP, NetFlow)
- Analiza logów systemowych (/var/log)

**Korzyści:**
- Elastic Beats (Filebeat, Metricbeat, Packetbeat) oferują gotową integrację
- Unified platform dla logów i metryk (alternatywa dla Prometheus + Loki)
- Grafana jako single pane of glass

### Kluczowe korzyści ze stosowania Elasticsearch z Grafaną

| Aspekt | Korzyść |
|--------|---------|
| **Wyszukiwanie** | Full-text search, regex, fuzzy matching – niedostępne w TSDB jak Prometheus/InfluxDB |
| **Skalowalność** | Clustering, sharding, replikacja – skalowanie horyzontalne do petabajtów danych |
| **Agregacje** | Zaawansowane aggregations (bucketing, metrics, pipeline) dla analiz biznesowych |
| **Ekosystem** | Elastic Stack (Kibana, Beats, Logstash, APM) – kompletne rozwiązanie observability |
| **Korelacja danych** | Grafana łączy Elasticsearch (logi/APM) z Prometheus (metryki) w jednym dashboardzie |
| **Wizualizacja** | Grafana oferuje bardziej elastyczne dashboardy niż Kibana dla multi-source correlation |

### Typowe decyzje projektowe

1. **Index strategy**: Time-based indices (daily, weekly, monthly) vs single index – wpływ na retention i performance
2. **Shard sizing**: 1 shard = 10–50 GB (guideline), zbyt dużo małych shards degraduje wydajność klastra
3. **Replicas**: Minimum 1 replica dla HA, więcej dla read-heavy workloads
4. **ILM (Index Lifecycle Management)**: Automatyzacja rollover, shrink, delete (hot-warm-cold-delete tiers)
5. **Mapping design**: Explicit mappings vs dynamic – kontrola typów, analyzers, keyword vs text fields
6. **Security**: Włączenie Elastic Security (authentication, TLS, RBAC) – konieczne w prod
7. **Monitoring Elasticsearch**: Monitorowanie samego klastra (cluster health, JVM, disk, query performance) w Grafanie lub Kibana Monitoring

### Typowe pułapki produkcyjne

- **Brak ILM**: Niekontrolowany wzrost indeksów, przepełnienie dysków, degradacja wydajności
- **Zbyt wiele małych shardów**: Overhead zarządzania, cluster state bloat, powolne zapytania
- **Nieodpowiednie mappings**: Błędne typy pól (np. IP jako text zamiast ip), brak keyword fields dla agregacji
- **Split brain**: Niewłaściwa konfiguracja `discovery.zen.minimum_master_nodes` w starszych wersjach (< 7.x)
- **JVM heap tuning**: Domyślne 1 GB niewystarczające, zalecane 50% RAM (max 31 GB z powodu Compressed OOPs)
- **Brak monitoringu klastra**: Cluster health, node failures, slow queries – monitoring infrastruktury Elasticsearch jest krytyczny
- **Bezpieczeństwo**: Exposing Elasticsearch bez authentication/TLS – podatność na ataki
- **Cardinality explosion w aggregations**: Zbyt duże aggregations (miliony buckets) mogą wyczerpać heap

### Wymagania środowiskowe (lab)

- Elasticsearch cluster (minimum 1 node, zalecane 3 dla HA, port 9200)
- Logstash lub Filebeat (do ingestion logów)
- Kibana (opcjonalnie, dla porównania z Grafaną, port 5601)
- Grafana (port 3000)
- Minimum 4 GB RAM dla Elasticsearch node (zalecane 8–16 GB)
- Połączenie sieciowe i dostęp do API

### Rezultaty integracji

- Uczestnik potrafi skonfigurować Elasticsearch jako datasource w Grafanie
- Umie tworzyć zapytania Lucene Query String i podstawowe Elasticsearch Query DSL
- Rozumie różnice między Elasticsearch a TSDB (Prometheus, InfluxDB) oraz Loki
- Potrafi zaprojektować index strategy z ILM dla production workloads
- Zna typowe zastosowania Elasticsearch w architekturze observability (logi, APM, SIEM, BI)
- Rozumie zagrożenia związane z niewłaściwą konfiguracją klastra (shard explosion, heap issues, brak security)

